# Qwen-Image & Qwen-Image-Edit çš„ LoRA è®­ç»ƒ

ç”± [FlyMy.AI](https://flymy.ai) æä¾›çš„å¼€æºå®ç°ï¼Œç”¨äºè®­ç»ƒ Qwen/Qwen-Image å’Œ Qwen/Qwen-Image-Edit æ¨¡å‹çš„ LoRAï¼ˆä½ç§©é€‚åº”ï¼‰å±‚ã€‚

<p align="center">
  <img src="./assets/flymy_transparent.png" alt="FlyMy.AI Logo" width="256">
</p>

## Star å†å²

[![Star History Chart](https://api.star-history.com/svg?repos=FlyMyAI/flymyai-lora-trainer&type=Date)](https://www.star-history.com/#FlyMyAI/flymyai-lora-trainer&Date)

## ğŸŒŸ å…³äº FlyMy.AI

GenAI çš„æ™ºèƒ½ä½“åŸºç¡€è®¾æ–½ã€‚FlyMy.AI æ˜¯ä¸€ä¸ªç”¨äºæ„å»ºå’Œè¿è¡Œ GenAI åª’ä½“æ™ºèƒ½ä½“çš„ B2B åŸºç¡€è®¾æ–½ã€‚

**ğŸ”— æœ‰ç”¨é“¾æ¥ï¼š**
- ğŸŒ [å®˜æ–¹ç½‘ç«™](https://flymy.ai)
- ğŸ“š [æ–‡æ¡£](https://docs.flymy.ai/intro)
- ğŸ’¬ [Discord ç¤¾åŒº](https://discord.com/invite/t6hPBpSebw)
- ğŸ¤— [é¢„è®­ç»ƒ LoRA æ¨¡å‹](https://huggingface.co/flymy-ai/qwen-image-realism-lora)
- ğŸ¦ [X (Twitter)](https://x.com/flymyai)
- ğŸ’¼ [LinkedIn](https://linkedin.com/company/flymyai)
- ğŸ“º [YouTube](https://youtube.com/@flymyai)
- ğŸ“¸ [Instagram](https://www.instagram.com/flymy_ai)

## ğŸš€ ç‰¹æ€§

- åŸºäº LoRA çš„é«˜æ•ˆå¾®è°ƒè®­ç»ƒ
- æ”¯æŒ Qwen-Image å’Œ Qwen-Image-Edit æ¨¡å‹
- å…¼å®¹ Hugging Face `diffusers`
- é€šè¿‡ YAML è½»æ¾é…ç½®
- åŸºäºæ§åˆ¶çš„ LoRA å›¾åƒç¼–è¾‘
- LoRA è®­ç»ƒçš„å¼€æºå®ç°
- Qwen-Image çš„å®Œæ•´è®­ç»ƒ

## ğŸ“… æ›´æ–°

**02.09.2025**
- âœ… æ·»åŠ äº† Qwen-Image å’Œ Qwen-Image-Edit çš„å®Œæ•´è®­ç»ƒ

**20.08.2025**
- âœ… æ·»åŠ äº† Qwen-Image-Edit LoRA è®­ç»ƒå™¨æ”¯æŒ

**09.08.2025**
- âœ… æ·»åŠ äº† < 24GiB GPU çš„è®­ç»ƒç®¡é“

**08.08.2025**
- âœ… æ·»åŠ äº†å…¨é¢çš„æ•°æ®é›†å‡†å¤‡è¯´æ˜
- âœ… æ·»åŠ äº†æ•°æ®é›†éªŒè¯è„šæœ¬ï¼ˆ`utils/validate_dataset.py`ï¼‰
- âœ… è®­ç»ƒæœŸé—´å†»ç»“æ¨¡å‹æƒé‡

## âš ï¸ é¡¹ç›®çŠ¶æ€

**ğŸš§ å¼€å‘ä¸­ï¼š** æˆ‘ä»¬æ­£åœ¨ç§¯ææ”¹è¿›ä»£ç å¹¶æ·»åŠ æµ‹è¯•è¦†ç›–ç‡ã€‚é¡¹ç›®å¤„äºå®Œå–„é˜¶æ®µä½†å·²å¯ä½¿ç”¨ã€‚

**ğŸ“‹ å¼€å‘è®¡åˆ’ï¼š**
- âœ… åŸºç¡€ä»£ç æ­£å¸¸å·¥ä½œ
- âœ… è®­ç»ƒåŠŸèƒ½å·²å®ç°
- ğŸ”„ æ€§èƒ½ä¼˜åŒ–è¿›è¡Œä¸­
- ğŸ”œ æµ‹è¯•è¦†ç›–ç‡å³å°†æ¨å‡º

---

## ğŸ“¦ å®‰è£…

**è¦æ±‚ï¼š**
- Python 3.10

1. å…‹éš†ä»“åº“å¹¶è¿›å…¥ç›®å½•ï¼š
   ```bash
   git clone https://github.com/FlyMyAI/flymyai-lora-trainer
   cd flymyai-lora-trainer
   ```

2. å®‰è£…æ‰€éœ€åŒ…ï¼š
   ```bash
   pip install -r requirements.txt
   ```

3. ä» GitHub å®‰è£…æœ€æ–°çš„ `diffusers`ï¼š
   ```bash
   pip install git+https://github.com/huggingface/diffusers
   ```

4. ä¸‹è½½é¢„è®­ç»ƒçš„ LoRA æƒé‡ï¼ˆå¯é€‰ï¼‰ï¼š
   ```bash
   # å…‹éš†åŒ…å« LoRA æƒé‡çš„ä»“åº“
   git clone https://huggingface.co/flymy-ai/qwen-image-realism-lora
   
   # æˆ–ä¸‹è½½ç‰¹å®šæ–‡ä»¶
   wget https://huggingface.co/flymy-ai/qwen-image-realism-lora/resolve/main/flymy_realism.safetensors
   ```

---

## ğŸ“ æ•°æ®å‡†å¤‡

### Qwen-Image è®­ç»ƒçš„æ•°æ®é›†ç»“æ„

è®­ç»ƒæ•°æ®åº”éµå¾ªä¸ Flux LoRA è®­ç»ƒç›¸åŒçš„æ ¼å¼ï¼Œæ¯ä¸ªå›¾åƒéƒ½æœ‰ä¸€ä¸ªåŒåçš„å¯¹åº”æ–‡æœ¬æ–‡ä»¶ï¼š

```
dataset/
â”œâ”€â”€ img1.png
â”œâ”€â”€ img1.txt
â”œâ”€â”€ img2.jpg
â”œâ”€â”€ img2.txt
â”œâ”€â”€ img3.png
â”œâ”€â”€ img3.txt
â””â”€â”€ ...
```

### Qwen-Image-Edit è®­ç»ƒçš„æ•°æ®é›†ç»“æ„

å¯¹äºåŸºäºæ§åˆ¶çš„å›¾åƒç¼–è¾‘ï¼Œæ•°æ®é›†åº”è¯¥ç»„ç»‡ä¸ºç›®æ ‡å›¾åƒ/æ ‡é¢˜å’Œæ§åˆ¶å›¾åƒçš„å•ç‹¬ç›®å½•ï¼š

```
dataset/
â”œâ”€â”€ images/           # ç›®æ ‡å›¾åƒåŠå…¶æ ‡é¢˜
â”‚   â”œâ”€â”€ image_001.jpg
â”‚   â”œâ”€â”€ image_001.txt
â”‚   â”œâ”€â”€ image_002.jpg
â”‚   â”œâ”€â”€ image_002.txt
â”‚   â””â”€â”€ ...
â””â”€â”€ control/          # æ§åˆ¶å›¾åƒ
    â”œâ”€â”€ image_001.jpg
    â”œâ”€â”€ image_002.jpg
    â””â”€â”€ ...
```

### æ•°æ®æ ¼å¼è¦æ±‚

1. **å›¾åƒ**ï¼šæ”¯æŒå¸¸è§æ ¼å¼ï¼ˆPNGã€JPGã€JPEGã€WEBPï¼‰
2. **æ–‡æœ¬æ–‡ä»¶**ï¼šåŒ…å«å›¾åƒæè¿°çš„çº¯æ–‡æœ¬æ–‡ä»¶
3. **æ–‡ä»¶å‘½å**ï¼šæ¯ä¸ªå›¾åƒå¿…é¡»æœ‰ä¸€ä¸ªåŒåçš„å¯¹åº”æ–‡æœ¬æ–‡ä»¶

### ç¤ºä¾‹æ•°æ®ç»“æ„

```
my_training_data/
â”œâ”€â”€ portrait_001.png
â”œâ”€â”€ portrait_001.txt
â”œâ”€â”€ landscape_042.jpg
â”œâ”€â”€ landscape_042.txt
â”œâ”€â”€ abstract_design.png
â”œâ”€â”€ abstract_design.txt
â””â”€â”€ style_reference.jpg
â””â”€â”€ style_reference.txt
```

### æ–‡æœ¬æ–‡ä»¶å†…å®¹ç¤ºä¾‹

**portrait_001.txt:**
```
ä¸€ä½æ£•è‰²å¤´å‘å¹´è½»å¥³æ€§çš„çœŸå®è‚–åƒï¼Œè‡ªç„¶å…‰ç…§ï¼Œä¸“ä¸šæ‘„å½±é£æ ¼
```

**landscape_042.txt:**
```
æ—¥è½æ—¶åˆ†çš„å±±æ™¯ï¼Œæˆå‰§æ€§äº‘å½©ï¼Œé»„é‡‘æ—¶åˆ»å…‰ç…§ï¼Œå¹¿è§’è§†å›¾
```

**abstract_design.txt:**
```
å…·æœ‰å‡ ä½•å½¢çŠ¶çš„ç°ä»£æŠ½è±¡è‰ºæœ¯ï¼Œé²œè‰³è‰²å½©ï¼Œæç®€ä¸»ä¹‰æ„å›¾
```

### æ•°æ®å‡†å¤‡æŠ€å·§

1. **å›¾åƒè´¨é‡**ï¼šä½¿ç”¨é«˜åˆ†è¾¨ç‡å›¾åƒï¼ˆæ¨è 1024x1024 æˆ–æ›´é«˜ï¼‰
2. **æè¿°è´¨é‡**ï¼šä¸ºæ‚¨çš„å›¾åƒç¼–å†™è¯¦ç»†ã€å‡†ç¡®çš„æè¿°
3. **ä¸€è‡´æ€§**ï¼šåœ¨æ•°æ®é›†ä¸­ä¿æŒä¸€è‡´çš„é£æ ¼å’Œè´¨é‡
4. **æ•°æ®é›†å¤§å°**ï¼šä¸ºäº†è·å¾—è‰¯å¥½ç»“æœï¼Œè‡³å°‘ä½¿ç”¨ 10-50 ä¸ªå›¾åƒ-æ–‡æœ¬å¯¹
5. **è§¦å‘è¯**ï¼šå¦‚æœè®­ç»ƒç‰¹å®šæ¦‚å¿µï¼Œåœ¨æè¿°ä¸­åŒ…å«ä¸€è‡´çš„è§¦å‘è¯
6. **è‡ªåŠ¨ç”Ÿæˆæè¿°**ï¼šæ‚¨å¯ä»¥ä½¿ç”¨ [Florence-2](https://huggingface.co/spaces/gokaygokay/Florence-2) è‡ªåŠ¨ç”Ÿæˆå›¾åƒæè¿°

### å¿«é€Ÿæ•°æ®éªŒè¯

æ‚¨å¯ä»¥ä½¿ç”¨åŒ…å«çš„éªŒè¯å·¥å…·éªŒè¯æ•°æ®ç»“æ„ï¼š

```bash
python utils/validate_dataset.py --path path/to/your/dataset
```

è¿™å°†æ£€æŸ¥ï¼š
- æ¯ä¸ªå›¾åƒéƒ½æœ‰å¯¹åº”çš„æ–‡æœ¬æ–‡ä»¶
- æ‰€æœ‰æ–‡ä»¶éƒ½éµå¾ªæ­£ç¡®çš„å‘½åçº¦å®š
- æŠ¥å‘Šä»»ä½•ç¼ºå¤±æ–‡ä»¶æˆ–ä¸ä¸€è‡´ä¹‹å¤„

---

## ğŸ åœ¨ < 24gb æ˜¾å­˜ä¸Šå¼€å§‹è®­ç»ƒ

è¦ä½¿ç”¨æ‚¨çš„é…ç½®æ–‡ä»¶ï¼ˆä¾‹å¦‚ `train_lora_4090.yaml`ï¼‰å¼€å§‹è®­ç»ƒï¼Œè¿è¡Œï¼š

```bash
accelerate launch train_4090.py --config ./train_configs/train_lora_4090.yaml
```
![ç¤ºä¾‹è¾“å‡º](./assets/Valentin_24gb.jpg)

## ğŸ å¼€å§‹è®­ç»ƒ

### Qwen-Image LoRA è®­ç»ƒ

è¦ä½¿ç”¨æ‚¨çš„é…ç½®æ–‡ä»¶ï¼ˆä¾‹å¦‚ `train_lora.yaml`ï¼‰å¼€å§‹è®­ç»ƒï¼Œè¿è¡Œï¼š

```bash
accelerate launch train.py --config ./train_configs/train_lora.yaml
```

ç¡®ä¿ `train_lora.yaml` æ­£ç¡®è®¾ç½®äº†æ•°æ®é›†ã€æ¨¡å‹ã€è¾“å‡ºç›®å½•å’Œå…¶ä»–å‚æ•°çš„è·¯å¾„ã€‚

### Qwen-Image å®Œæ•´è®­ç»ƒ

è¦ä½¿ç”¨æ‚¨çš„é…ç½®æ–‡ä»¶ï¼ˆä¾‹å¦‚ `train_full_qwen_image.yaml`ï¼‰å¼€å§‹è®­ç»ƒï¼Œè¿è¡Œï¼š

```bash
accelerate launch train_full_qwen_image.py --config ./train_configs/train_full_qwen_image.yaml
```

ç¡®ä¿ `train_full_qwen_image.yaml` æ­£ç¡®è®¾ç½®äº†æ•°æ®é›†ã€æ¨¡å‹ã€è¾“å‡ºç›®å½•å’Œå…¶ä»–å‚æ•°çš„è·¯å¾„ã€‚

#### åŠ è½½è®­ç»ƒçš„å®Œæ•´æ¨¡å‹

è®­ç»ƒåï¼Œæ‚¨å¯ä»¥ä»æ£€æŸ¥ç‚¹ç›®å½•åŠ è½½è®­ç»ƒçš„æ¨¡å‹è¿›è¡Œæ¨ç†ã€‚

**ç®€å•ç¤ºä¾‹ï¼š**

```python
from diffusers import QwenImagePipeline, QwenImageTransformer2DModel, AutoencoderKLQwenImage
import torch
from omegaconf import OmegaConf
import os

def load_trained_model(checkpoint_path):
    """ä»æ£€æŸ¥ç‚¹åŠ è½½è®­ç»ƒçš„æ¨¡å‹"""
    print(f"ä»ä»¥ä¸‹ä½ç½®åŠ è½½è®­ç»ƒçš„æ¨¡å‹ï¼š{checkpoint_path}")
    
    # åŠ è½½é…ç½®ä»¥è·å–åŸå§‹æ¨¡å‹è·¯å¾„
    config_path = os.path.join(checkpoint_path, "config.yaml")
    config = OmegaConf.load(config_path)
    original_model_path = config.pretrained_model_name_or_path
    
    # åŠ è½½è®­ç»ƒçš„ transformer
    transformer_path = os.path.join(checkpoint_path, "transformer")
    transformer = QwenImageTransformer2DModel.from_pretrained(
        transformer_path,
        torch_dtype=torch.bfloat16,
        low_cpu_mem_usage=True
    )
    transformer.to("cuda")
    transformer.eval()
    
    # ä»åŸå§‹æ¨¡å‹åŠ è½½ VAE
    vae = AutoencoderKLQwenImage.from_pretrained(
        original_model_path,
        subfolder="vae",
        torch_dtype=torch.bfloat16
    )
    vae.to("cuda")
    vae.eval()
    
    # åˆ›å»ºç®¡é“
    pipe = QwenImagePipeline.from_pretrained(
        original_model_path,
        transformer=transformer,
        vae=vae,
        torch_dtype=torch.bfloat16
    )
    pipe.to("cuda")
    
    print("æ¨¡å‹åŠ è½½æˆåŠŸï¼")
    return pipe

# ä½¿ç”¨æ–¹æ³•
checkpoint_path = "/path/to/your/checkpoint"
pipe = load_trained_model(checkpoint_path)

# ç”Ÿæˆå›¾åƒ
prompt = "ç¾ä¸½çš„å±±æ¹–é£æ™¯"
image = pipe(
    prompt=prompt,
    width=768,
    height=768,
    num_inference_steps=30,
    true_cfg_scale=5,
    generator=torch.Generator(device="cuda").manual_seed(42)
)

# ä¿å­˜ç»“æœ
output_image = image.images[0]
output_image.save("generated_image.png")
```

**å®Œæ•´ç¤ºä¾‹è„šæœ¬ï¼š**

```bash
python inference_trained_model_gpu_optimized.py
```

**æ£€æŸ¥ç‚¹ç»“æ„ï¼š**

è®­ç»ƒçš„æ¨¡å‹ä»¥ä»¥ä¸‹ç»“æ„ä¿å­˜ï¼š
```
checkpoint/
â”œâ”€â”€ config.yaml          # è®­ç»ƒé…ç½®
â””â”€â”€ transformer/         # è®­ç»ƒçš„ transformer æƒé‡
    â”œâ”€â”€ config.json
    â”œâ”€â”€ diffusion_pytorch_model.safetensors.index.json
    â””â”€â”€ diffusion_pytorch_model-00001-of-00005.safetensors
    â””â”€â”€ ... (å¤šä¸ªåˆ†ç‰‡æ–‡ä»¶)
```

### Qwen-Image-Edit LoRA è®­ç»ƒ

å¯¹äºåŸºäºæ§åˆ¶çš„å›¾åƒç¼–è¾‘è®­ç»ƒï¼Œä½¿ç”¨ä¸“é—¨çš„è®­ç»ƒè„šæœ¬ï¼š

```bash
accelerate launch train_qwen_edit_lora.py --config ./train_configs/train_lora_qwen_edit.yaml
```

#### Qwen-Image-Edit çš„é…ç½®

é…ç½®æ–‡ä»¶ `train_lora_qwen_edit.yaml` åº”åŒ…æ‹¬ï¼š

- `img_dir`ï¼šç›®æ ‡å›¾åƒå’Œæ ‡é¢˜ç›®å½•çš„è·¯å¾„ï¼ˆä¾‹å¦‚ `./extracted_dataset/train/images`ï¼‰
- `control_dir`ï¼šæ§åˆ¶å›¾åƒç›®å½•çš„è·¯å¾„ï¼ˆä¾‹å¦‚ `./extracted_dataset/train/control`ï¼‰
- å…¶ä»–æ ‡å‡† LoRA è®­ç»ƒå‚æ•°

## ğŸ§ª ä½¿ç”¨

### Qwen-Image-Edit å®Œæ•´è®­ç»ƒ

è¦ä½¿ç”¨æ‚¨çš„é…ç½®æ–‡ä»¶ï¼ˆä¾‹å¦‚ `train_full_qwen_edit.yaml`ï¼‰å¼€å§‹è®­ç»ƒï¼Œè¿è¡Œï¼š

```bash
accelerate launch train_full_qwen_edit.py --config ./train_configs/train_full_qwen_edit.yaml
```

---

### ğŸ”§ Qwen-Image åˆå§‹åŒ–

```python
from diffusers import DiffusionPipeline
import torch

model_name = "Qwen/Qwen-Image"

# åŠ è½½ç®¡é“
if torch.cuda.is_available():
    torch_dtype = torch.bfloat16
    device = "cuda"
else:
    torch_dtype = torch.float32
    device = "cpu"

pipe = DiffusionPipeline.from_pretrained(model_name, torch_dtype=torch_dtype)
pipe = pipe.to(device)
```

### ğŸ”§ Qwen-Image-Edit åˆå§‹åŒ–

```python
from diffusers import QwenImageEditPipeline
import torch
from PIL import Image

# åŠ è½½ç®¡é“
pipeline = QwenImageEditPipeline.from_pretrained("Qwen/Qwen-Image-Edit")
pipeline.to(torch.bfloat16)
pipeline.to("cuda")
```

### ğŸ”Œ åŠ è½½ LoRA æƒé‡

å¯¹äº Qwen-Imageï¼š
```python
# åŠ è½½ LoRA æƒé‡
pipe.load_lora_weights('flymy-ai/qwen-image-realism-lora', adapter_name="lora")
```

å¯¹äº Qwen-Image-Editï¼š
```python
# åŠ è½½è®­ç»ƒçš„ LoRA æƒé‡
pipeline.load_lora_weights("/path/to/your/trained/lora/pytorch_lora_weights.safetensors")
```

### ğŸ¨ ä½¿ç”¨ Qwen-Image LoRA ç”Ÿæˆå›¾åƒ
æ‚¨å¯ä»¥åœ¨[è¿™é‡Œ](https://huggingface.co/flymy-ai/qwen-image-realism-lora)æ‰¾åˆ° LoRA æƒé‡

æ— éœ€è§¦å‘è¯
```python
prompt = '''éæ´²è£”é’å°‘å¹´å¥³æ€§çš„è¶…ç°å®ä¸»ä¹‰è‚–åƒï¼Œå®é™å¹³å’Œï¼ŒåŒè‡‚äº¤å‰ï¼Œæˆå‰§æ€§å·¥ä½œå®¤ç¯å…‰ç…§æ˜ï¼Œé˜³å…‰å…¬å›­èƒŒæ™¯ï¼Œä½©æˆ´ç²¾è‡´ç å®ï¼Œå››åˆ†ä¹‹ä¸‰è§†è§’ï¼Œé˜³å…‰äº²å»çš„è‚Œè‚¤å¸¦æœ‰è‡ªç„¶ç‘•ç–µï¼Œæ¾æ•£çš„é½è‚©å·å‘ï¼Œå¾®çœ¯çš„çœ¼ç›ï¼Œç¯å¢ƒè¡—å¤´è‚–åƒï¼ŒTæ¤ä¸Šæœ‰"FLYMY AI"æ–‡å­—ã€‚'''
negative_prompt = " "
image = pipe(
    prompt=prompt,
    negative_prompt=negative_prompt,
    width=1024,
    height=1024,
    num_inference_steps=50,
    true_cfg_scale=5,
    generator=torch.Generator(device="cuda").manual_seed(346346)
)

# æ˜¾ç¤ºå›¾åƒï¼ˆåœ¨ Jupyter ä¸­æˆ–ä¿å­˜åˆ°æ–‡ä»¶ï¼‰
image.show()
# æˆ–
image.save("output.png")
```

### ğŸ¨ ä½¿ç”¨ Qwen-Image-Edit LoRA ç¼–è¾‘å›¾åƒ

```python
# åŠ è½½è¾“å…¥å›¾åƒ
image = Image.open("/path/to/your/input/image.jpg").convert("RGB")

# å®šä¹‰ç¼–è¾‘æç¤º
prompt = "åœ¨åŒä¸€åœºæ™¯ä¸­æ‹æ‘„äººç‰©è¿œç¦»ç›¸æœºçš„é•œå¤´ï¼Œä¿æŒç›¸æœºç¨³å®šä»¥ä¿æŒå¯¹ä¸­å¿ƒä¸»ä½“çš„ç„¦ç‚¹ï¼Œé€æ¸ç¼©å°ä»¥æ•æ‰æ›´å¤šå‘¨å›´ç¯å¢ƒï¼Œéšç€äººç‰©åœ¨è¿œå¤„å˜å¾—ä¸é‚£ä¹ˆè¯¦ç»†ã€‚"

# ç”Ÿæˆç¼–è¾‘çš„å›¾åƒ
inputs = {
    "image": image,
    "prompt": prompt,
    "generator": torch.manual_seed(0),
    "true_cfg_scale": 4.0,
    "negative_prompt": " ",
    "num_inference_steps": 50,
}

with torch.inference_mode():
    output = pipeline(**inputs)
    output_image = output.images[0]
    output_image.save("edited_image.png")
```

### ğŸ–¼ï¸ ç¤ºä¾‹è¾“å‡º - Qwen-Image

![ç¤ºä¾‹è¾“å‡º](./assets/lora.png)

### ğŸ–¼ï¸ ç¤ºä¾‹è¾“å‡º - Qwen-Image-Edit

**è¾“å…¥å›¾åƒï¼š**

![è¾“å…¥å›¾åƒ](./assets/qie2_orig.jpg)

**æç¤ºï¼š** 
"åœ¨åŒä¸€åœºæ™¯ä¸­æ‹æ‘„å·¦æ‰‹å›ºå®šåˆ‡èœæ¿è¾¹ç¼˜è€Œå³æ‰‹å€¾æ–œå®ƒçš„é•œå¤´ï¼Œä½¿åˆ‡ç¢çš„ç•ªèŒ„æ»‘å…¥é”…ä¸­ï¼Œç›¸æœºè§’åº¦ç¨å¾®å‘å·¦ç§»åŠ¨ä»¥æ›´å¤šåœ°èšç„¦åœ¨é”…ä¸Šã€‚"

**ä¸ä½¿ç”¨ LoRA çš„è¾“å‡ºï¼š**

![ä¸ä½¿ç”¨ LoRA çš„è¾“å‡º](./assets/qie2_orig.jpg)

**ä½¿ç”¨ LoRA çš„è¾“å‡ºï¼š**

![ä½¿ç”¨ LoRA çš„è¾“å‡º](./assets/qie2_lora.jpg)

---

## ğŸ›ï¸ ä¸ ComfyUI ä¸€èµ·ä½¿ç”¨

æˆ‘ä»¬æä¾›äº†ä¸€ä¸ªå³ç”¨å‹çš„ ComfyUI å·¥ä½œæµï¼Œå¯ä¸æˆ‘ä»¬è®­ç»ƒçš„ LoRA æ¨¡å‹é…åˆä½¿ç”¨ã€‚æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤è®¾ç½®å’Œä½¿ç”¨å·¥ä½œæµï¼š

### è®¾ç½®è¯´æ˜

1. **ä¸‹è½½æœ€æ–°çš„ ComfyUI**ï¼š
   - è®¿é—® [ComfyUI GitHub ä»“åº“](https://github.com/comfyanonymous/ComfyUI)
   - å…‹éš†æˆ–ä¸‹è½½æœ€æ–°ç‰ˆæœ¬

2. **å®‰è£… ComfyUI**ï¼š
   - æŒ‰ç…§ [ComfyUI ä»“åº“](https://github.com/comfyanonymous/ComfyUI?tab=readme-ov-file#installing) çš„å®‰è£…è¯´æ˜
   - ç¡®ä¿æ‰€æœ‰ä¾èµ–é¡¹éƒ½æ­£ç¡®å®‰è£…

3. **ä¸‹è½½ Qwen-Image æ¨¡å‹æƒé‡**ï¼š
   - å‰å¾€ [Qwen-Image ComfyUI æƒé‡](https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/tree/main)
   - ä¸‹è½½æ‰€æœ‰æ¨¡å‹æ–‡ä»¶

4. **å°† Qwen-Image æƒé‡æ”¾å…¥ ComfyUI**ï¼š
   - å°†ä¸‹è½½çš„ Qwen-Image æ¨¡å‹æ–‡ä»¶å¤åˆ¶åˆ° `ComfyUI/models/` ä¸­çš„ç›¸åº”æ–‡ä»¶å¤¹
   - æŒ‰ç…§æ¨¡å‹ä»“åº“ä¸­æŒ‡å®šçš„æ–‡ä»¶å¤¹ç»“æ„

5. **ä¸‹è½½æˆ‘ä»¬çš„é¢„è®­ç»ƒ LoRA æƒé‡**ï¼š
   - è®¿é—® [flymy-ai/qwen-image-lora](https://huggingface.co/flymy-ai/qwen-image-lora)
   - ä¸‹è½½ LoRA `.safetensors` æ–‡ä»¶

6. **å°† LoRA æƒé‡æ”¾å…¥ ComfyUI**ï¼š
   - å°† LoRA æ–‡ä»¶ `flymy-ai/qwen-image-lora/pytorch_lora_weights.safetensors` å¤åˆ¶åˆ° `ComfyUI/models/loras/`

7. **åŠ è½½å·¥ä½œæµ**ï¼š
   - åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€ ComfyUI
   - åŠ è½½ä½äºæ­¤ä»“åº“ä¸­çš„å·¥ä½œæµæ–‡ä»¶ `qwen_image_lora_example.json`
   - å·¥ä½œæµå·²é¢„é…ç½®ä¸ºä¸æˆ‘ä»¬çš„ LoRA æ¨¡å‹é…åˆä½¿ç”¨

### å·¥ä½œæµç‰¹æ€§

- âœ… ä¸º Qwen-Image + LoRA æ¨ç†é¢„é…ç½®
- âœ… ä¼˜åŒ–è®¾ç½®ä»¥è·å¾—æœ€ä½³è´¨é‡è¾“å‡º
- âœ… è½»æ¾è°ƒæ•´æç¤ºå’Œå‚æ•°
- âœ… å…¼å®¹æˆ‘ä»¬æ‰€æœ‰è®­ç»ƒçš„ LoRA æ¨¡å‹

ComfyUI å·¥ä½œæµæä¾›äº†ä¸€ä¸ªç”¨æˆ·å‹å¥½çš„ç•Œé¢ï¼Œç”¨äºä½¿ç”¨æˆ‘ä»¬è®­ç»ƒçš„ LoRA æ¨¡å‹ç”Ÿæˆå›¾åƒï¼Œæ— éœ€ç¼–å†™ Python ä»£ç ã€‚

### ğŸ–¼ï¸ å·¥ä½œæµæˆªå›¾

![ComfyUI å·¥ä½œæµ](./assets/comfyui_workflow.png)

---

## ğŸ¤ æ”¯æŒ

å¦‚æœæ‚¨æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·åŠ å…¥æˆ‘ä»¬çš„ç¤¾åŒºï¼š
- ğŸŒ [FlyMy.AI](https://flymy.ai)
- ğŸ’¬ [Discord ç¤¾åŒº](https://discord.com/invite/t6hPBpSebw)
- ğŸ¦ [åœ¨ X ä¸Šå…³æ³¨æˆ‘ä»¬](https://x.com/flymyai)
- ğŸ’¼ [åœ¨ LinkedIn ä¸Šè”ç³»](https://linkedin.com/company/flymyai)
- ğŸ“§ [æ”¯æŒ](mailto:support@flymy.ai)

**â­ å¦‚æœæ‚¨å–œæ¬¢è¿™ä¸ªä»“åº“ï¼Œåˆ«å¿˜äº†ç»™å®ƒç‚¹æ˜Ÿï¼**
