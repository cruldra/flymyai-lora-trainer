import marimo

__generated_with = "0.16.5"
app = marimo.App(width="medium")


@app.cell
def _():
    import marimo as mo
    return (mo,)


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    # MLOpså®Œæ•´è“å›¾ï¼šæ•°æ®å’Œç®¡é“å·¥ç¨‹ï¼ˆå«å®ç°ï¼‰

    MLOpså’ŒLLMOpsé€Ÿæˆè¯¾ç¨‹â€”â€”ç¬¬7éƒ¨åˆ†

    ## ğŸ“š æœ¬ç« æ¦‚è§ˆ

    åœ¨æœ¬ç« ä¸­ï¼Œæˆ‘ä»¬å°†æ·±å…¥æ¢è®¨MLOpsä¸­çš„ä¸¤ä¸ªå…³é”®ç»„ä»¶ï¼š

    1. **Apache Spark**ï¼šç”¨äºå¤§è§„æ¨¡åˆ†å¸ƒå¼æ•°æ®å¤„ç†
    2. **Prefect**ï¼šç”¨äºå·¥ä½œæµç¼–æ’å’Œè°ƒåº¦

    è¿™ä¸¤ä¸ªå·¥å…·åœ¨ç°ä»£MLOpsæµç¨‹ä¸­æ‰®æ¼”ç€è‡³å…³é‡è¦çš„è§’è‰²ï¼Œå¸®åŠ©æˆ‘ä»¬å¤„ç†æµ·é‡æ•°æ®å¹¶è‡ªåŠ¨åŒ–å¤æ‚çš„æœºå™¨å­¦ä¹ ç®¡é“ã€‚
    """
    )
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    ## ğŸŒŸ Apache Sparkåˆ†å¸ƒå¼æ•°æ®å¤„ç†

    ### ä¸ºä»€ä¹ˆéœ€è¦Sparkï¼Ÿ

    éšç€æ•°æ®é‡çš„å¢é•¿ï¼Œå•æœºå·¥å…·ï¼ˆå¦‚Pandasã€NumPyï¼‰å¯èƒ½ä¼šå¼€å§‹åŠ›ä¸ä»å¿ƒã€‚è¿™æ—¶å°±éœ€è¦Apache Sparkâ€”â€”ä¸€ä¸ªå¹¿æ³›ç”¨äºå¤§æ•°æ®å¤„ç†çš„åˆ†å¸ƒå¼è®¡ç®—å¼•æ“ã€‚

    ### Sparkæ˜¯ä»€ä¹ˆï¼Ÿ

    Sparkæ˜¯ä¸€ä¸ªé›†ç¾¤è®¡ç®—æ¡†æ¶ï¼Œæä¾›äº†åˆ†å¸ƒå¼æ•°æ®ç»“æ„ï¼ˆå¦‚å¼¹æ€§åˆ†å¸ƒå¼æ•°æ®é›†RDDå’Œæ›´é«˜çº§çš„DataFrameï¼‰åŠå…¶æ“ä½œçš„APIã€‚

    **æ ¸å¿ƒç‰¹ç‚¹ï¼š**

    - **åˆ†å¸ƒå¼è®¡ç®—**ï¼šå°†æ•°æ®åˆ†å¸ƒåœ¨å¤šå°æœºå™¨ä¸Šå¹¶è¡Œå¤„ç†
    - **å†…å­˜è®¡ç®—**ï¼šå°½å¯èƒ½åœ¨å†…å­˜ä¸­å¤„ç†æ•°æ®ï¼Œé€Ÿåº¦å¿«
    - **å¤šè¯­è¨€æ”¯æŒ**ï¼šScalaã€Pythonï¼ˆPySparkï¼‰ã€Javaã€Rç­‰
    - **ä¸°å¯Œçš„ç”Ÿæ€**ï¼šåŒ…å«Spark SQLã€MLlibã€GraphXç­‰ç»„ä»¶

    ### Sparkåœ¨MLä¸­çš„ä¸¤ä¸ªå…³é”®æ–¹é¢

    1. **DataFrame API**ï¼šç±»ä¼¼äºPandas DataFrameï¼Œä½†æ˜¯åˆ†å¸ƒå¼çš„
    2. **Spark MLlib**ï¼šåŒ…å«å¯ä»¥åˆ†å¸ƒå¼è¿è¡Œçš„æœºå™¨å­¦ä¹ ç®—æ³•å’ŒPipeline
    """
    )
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    ## ğŸ“Š Spark DataFrame

    Sparkçš„DataFrameåœ¨æ¦‚å¿µä¸Šç±»ä¼¼äºåˆ†å¸ƒåœ¨é›†ç¾¤ä¸­çš„è¡¨ã€‚ä½ å¯ä»¥æ‰§è¡Œç±»ä¼¼SQLçš„æ“ä½œï¼šè¿‡æ»¤ã€è¿æ¥ã€åˆ†ç»„ç­‰ï¼ŒSparkä¼šè‡ªåŠ¨å¹¶è¡ŒåŒ–è¿™äº›æ“ä½œã€‚

    ### åº•å±‚åŸç†

    - åŸºäºRDDæ„å»º
    - é€šè¿‡CatalystæŸ¥è¯¢ä¼˜åŒ–å™¨æä¾›ä¼˜åŒ–
    - æ•°æ®è¢«åˆ†åŒºå¹¶åˆ†å¸ƒåœ¨ä¸åŒçš„workerèŠ‚ç‚¹ä¸Š
    - æ¯ä¸ªworkeråªå¤„ç†è‡ªå·±çš„æ•°æ®åˆ†åŒº

    ### Sparkåœ¨ML ETLä¸­çš„åº”ç”¨

    è®¸å¤šæ•°æ®å·¥ç¨‹ç®¡é“ä½¿ç”¨Sparkæ¥å®Œæˆç¹é‡çš„å·¥ä½œï¼š

    - ä»æ•°æ®æ¹–è¯»å–æ•°æ®
    - è¿æ¥å¤§å‹è¡¨
    - è®¡ç®—ç‰¹å¾ï¼ˆå¦‚èšåˆï¼‰
    - è¾“å‡ºç»“æœåˆ°å­˜å‚¨ï¼ˆå¦‚Parquetæ–‡ä»¶ï¼‰
    - ç›´æ¥é€šè¿‡MLlibè®­ç»ƒæ¨¡å‹
    """
    )
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    ## ğŸ”§ Spark ML Pipelineç¤ºä¾‹

    è®©æˆ‘ä»¬é€šè¿‡ä¸€ä¸ªå®Œæ•´çš„ç¤ºä¾‹æ¥ç†è§£Spark ML Pipelineçš„å·¥ä½œåŸç†ã€‚

    ### ç¤ºä¾‹åœºæ™¯ï¼šæ—¶é—´åºåˆ—å›å½’

    æˆ‘ä»¬å°†æ„å»ºä¸€ä¸ªåŒ…å«ä»¥ä¸‹æ­¥éª¤çš„Pipelineï¼š

    1. **æ•°æ®ç”Ÿæˆ**ï¼šåˆ›å»ºåˆæˆçš„æ—¶é—´åºåˆ—æ•°æ®
    2. **æ—¶é—´åˆ†å‰²**ï¼šæŒ‰æ—¶é—´åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
    3. **ç‰¹å¾å·¥ç¨‹**ï¼šæå–æ—¶é—´ç‰¹å¾ï¼ˆå¦‚å°æ—¶ï¼‰
    4. **æ•°æ®é¢„å¤„ç†**ï¼šç¼ºå¤±å€¼å¡«å……
    5. **ç‰¹å¾ç»„è£…**ï¼šå°†ç‰¹å¾ç»„åˆæˆå‘é‡
    6. **æ¨¡å‹è®­ç»ƒ**ï¼šçº¿æ€§å›å½’
    7. **æ¨¡å‹è¯„ä¼°**ï¼šè®¡ç®—RÂ²åˆ†æ•°
    """
    )
    return


@app.cell
def _():
    # æ³¨æ„ï¼šè¿™æ˜¯æ¼”ç¤ºä»£ç ï¼Œéœ€è¦å®‰è£…PySpark
    # pip install pyspark

    print("ğŸ”§ Spark ML Pipelineæ¼”ç¤º")
    print("=" * 50)

    # ç”±äºåœ¨æœ¬åœ°ç¯å¢ƒä¸­è¿è¡Œå®Œæ•´çš„Sparkå¯èƒ½æ¯”è¾ƒå¤æ‚ï¼Œ
    # è¿™é‡Œæˆ‘ä»¬å±•ç¤ºå…³é”®æ¦‚å¿µå’Œä»£ç ç»“æ„

    spark_pipeline_code = """
    from pyspark.sql import SparkSession
    from pyspark.ml import Pipeline
    from pyspark.ml.feature import Imputer, VectorAssembler
    from pyspark.ml.regression import LinearRegression
    from pyspark.ml.evaluation import RegressionEvaluator
    import pyspark.sql.functions as F

    # 1. åˆ›å»ºSparkä¼šè¯
    spark = SparkSession.builder \\
        .appName("SimpleSparkMLPipeline") \\
        .master("local[*]") \\
        .config("spark.driver.memory", "4g") \\
        .getOrCreate()

    spark.sparkContext.setLogLevel("WARN")

    # 2. ç”Ÿæˆåˆæˆæ•°æ®
    n_rows = 10_000
    start_ts = int(F.unix_timestamp(F.lit("2024-01-01 00:00:00")).cast("long"))

    df = spark.range(n_rows) \\
        .withColumn("ts", start_ts + (F.col("id") * 60)) \\
        .withColumn("ds", F.from_unixtime(F.col("ts")).cast("timestamp")) \\
        .withColumn("feature_a", F.randn(seed=42)) \\
        .withColumn("feature_b", F.rand(seed=1337) * 10.0) \\
        .withColumn("y", 2.0*F.col("feature_a") + 0.3*F.col("feature_b") + F.randn(seed=7)*0.5) \\
        .drop("ts")

    # 3. æ—¶é—´åˆ†å‰²
    split_date = "2024-01-08 00:00:00"
    train = df.filter(F.col("ds") < split_date)
    test = df.filter(F.col("ds") >= split_date)

    # 4. ç‰¹å¾å·¥ç¨‹
    train = train.withColumn("hour", F.hour(F.col("ds")).cast("double"))
    test = test.withColumn("hour", F.hour(F.col("ds")).cast("double"))

    # 5. å®šä¹‰Pipeline
    imputer = Imputer(
        inputCols=["hour", "feature_a", "feature_b"],
        outputCols=["hour_imp", "feature_a_imp", "feature_b_imp"]
    )

    assembler = VectorAssembler(
        inputCols=["hour_imp", "feature_a_imp", "feature_b_imp"],
        outputCol="features"
    )

    lr = LinearRegression(labelCol="y", featuresCol="features")

    pipeline = Pipeline(stages=[imputer, assembler, lr])

    # 6. è®­ç»ƒæ¨¡å‹
    model = pipeline.fit(train)

    # 7. è¯„ä¼°æ¨¡å‹
    predictions = model.transform(test)
    evaluator = RegressionEvaluator(labelCol="y", predictionCol="prediction", metricName="r2")
    r2 = evaluator.evaluate(predictions)

    print(f"æµ‹è¯•é›†RÂ²åˆ†æ•°: {r2:.4f}")

    spark.stop()
    """

    print("\nğŸ“ Spark ML Pipelineä»£ç ç»“æ„ï¼š")
    print(spark_pipeline_code)

    return (spark_pipeline_code,)


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    ## ğŸ” Spark Pipelineå·¥ä½œæµç¨‹è¯¦è§£

    ### æ­¥éª¤1ï¼šSparkä¼šè¯åˆå§‹åŒ–

    ```python
    spark = SparkSession.builder \\
        .appName("SimpleSparkMLPipeline") \\
        .master("local[*]") \\
        .config("spark.driver.memory", "4g") \\
        .getOrCreate()
    ```

    - åˆ›å»ºæœ¬åœ°Sparkä¼šè¯
    - ä½¿ç”¨æ‰€æœ‰å¯ç”¨CPUæ ¸å¿ƒ
    - é™åˆ¶é©±åŠ¨å†…å­˜ä¸º4GB
    - è®¾ç½®æ—¥å¿—çº§åˆ«ä¸ºWARN

    ### æ­¥éª¤2ï¼šæ•°æ®ç”Ÿæˆ

    - åˆ›å»º10,000è¡Œæ—¶é—´åºåˆ—æ•°æ®
    - æ¯è¡Œé—´éš”1åˆ†é’Ÿ
    - ç”Ÿæˆä¸¤ä¸ªç‰¹å¾ï¼šfeature_aï¼ˆé«˜æ–¯åˆ†å¸ƒï¼‰ã€feature_bï¼ˆå‡åŒ€åˆ†å¸ƒï¼‰
    - ç›®æ ‡å˜é‡y = 2.0*feature_a + 0.3*feature_b + å™ªå£°

    ### æ­¥éª¤3ï¼šæ—¶é—´åˆ†å‰²

    - æŒ‰æ—¶é—´æˆ³åˆ†å‰²è®­ç»ƒé›†å’Œæµ‹è¯•é›†
    - é¿å…æ•°æ®æ³„æ¼ï¼ˆæœªæ¥ä¿¡æ¯ä¸ä¼šå½±å“è¿‡å»çš„é¢„æµ‹ï¼‰

    ### æ­¥éª¤4ï¼šç‰¹å¾å·¥ç¨‹

    - ä»æ—¶é—´æˆ³ä¸­æå–å°æ—¶ç‰¹å¾
    - è¿™æ˜¯ä¸€ä¸ªç¡®å®šæ€§è½¬æ¢ï¼Œä¸ä¼šå¯¼è‡´æ³„æ¼

    ### æ­¥éª¤5ï¼šPipelineå®šä¹‰

    - **Imputer**ï¼šå¤„ç†ç¼ºå¤±å€¼ï¼ˆè™½ç„¶åˆæˆæ•°æ®æ²¡æœ‰ç¼ºå¤±å€¼ï¼‰
    - **VectorAssembler**ï¼šå°†ç‰¹å¾ç»„åˆæˆå‘é‡
    - **LinearRegression**ï¼šçº¿æ€§å›å½’æ¨¡å‹

    ### æ­¥éª¤6ï¼šè®­ç»ƒ

    - Pipelineåœ¨è®­ç»ƒé›†ä¸Šfit
    - æ‰€æœ‰è½¬æ¢å™¨çš„å‚æ•°éƒ½ä»è®­ç»ƒé›†å­¦ä¹ 

    ### æ­¥éª¤7ï¼šè¯„ä¼°

    - åœ¨æµ‹è¯•é›†ä¸Štransform
    - è®¡ç®—RÂ²åˆ†æ•°
    """
    )
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    ## âš–ï¸ Pandas vs Sparkï¼šä½•æ—¶ä½¿ç”¨å“ªä¸ªï¼Ÿ

    ### Pandasçš„ä¼˜åŠ¿

    **é€‚ç”¨åœºæ™¯ï¼š**
    - æ•°æ®é‡ < å‡ ç™¾ä¸‡è¡Œ
    - æ•°æ®å¤§å° < å‡ GB
    - å•æœºå†…å­˜è¶³å¤Ÿ
    - å¿«é€ŸåŸå‹å¼€å‘
    - æ¢ç´¢æ€§æ•°æ®åˆ†æ

    **ç‰¹ç‚¹ï¼š**
    - âœ… ä½å¼€é”€ï¼Œå¯åŠ¨å¿«
    - âœ… ç®€å•æ˜“ç”¨
    - âœ… ä¸°å¯Œçš„API
    - âœ… å³æ—¶æ‰§è¡Œï¼ˆeager executionï¼‰
    - âŒ å—é™äºå•æœºå†…å­˜
    - âŒ æ— æ³•å¤„ç†è¶…å¤§æ•°æ®é›†

    ### Sparkçš„ä¼˜åŠ¿

    **é€‚ç”¨åœºæ™¯ï¼š**
    - æ•°æ®é‡ > æ•°åäº¿è¡Œ
    - æ•°æ®åˆ†å¸ƒåœ¨é›†ç¾¤ä¸­
    - éœ€è¦å¤æ‚çš„shuffleæ“ä½œ
    - æ•°æ®å­˜å‚¨åœ¨HDFS/æ•°æ®æ¹–
    - éœ€è¦åˆ†å¸ƒå¼è®¡ç®—

    **ç‰¹ç‚¹ï¼š**
    - âœ… å¯æ‰©å±•åˆ°é›†ç¾¤
    - âœ… å¤„ç†è¶…å¤§æ•°æ®é›†
    - âœ… å®¹é”™æœºåˆ¶
    - âœ… æ‡’æ‰§è¡Œï¼ˆlazy executionï¼‰
    - âœ… å¯ä»¥spillåˆ°ç£ç›˜
    - âŒ å¯åŠ¨å¼€é”€å¤§
    - âŒ å°æ•°æ®é›†ä¸Šå¯èƒ½æ›´æ…¢
    - âŒ è°ƒè¯•ç›¸å¯¹å›°éš¾
    """
    )
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    ## ğŸ§ª Pandas vs Sparkï¼šæ‡’æ‰§è¡Œæ¼”ç¤º

    è®©æˆ‘ä»¬é€šè¿‡ä¸€ä¸ªå®é™…ä¾‹å­æ¥ç†è§£Pandasçš„å³æ—¶æ‰§è¡Œå’ŒSparkçš„æ‡’æ‰§è¡Œçš„åŒºåˆ«ã€‚

    ### åœºæ™¯ï¼šç”Ÿæˆå¤§é‡æ•°æ®

    æˆ‘ä»¬å°†å°è¯•ç”Ÿæˆ1äº¿è¡Œæ•°æ®ï¼Œçœ‹çœ‹Pandaså’ŒSparkçš„è¡¨ç°ã€‚
    """
    )
    return


@app.cell
def _():
    import numpy as np
    import pandas as pd

    print("ğŸ§ª Pandas vs Sparkæ‰§è¡Œæ¨¡å¼å¯¹æ¯”")
    print("=" * 50)

    # Pandasç¤ºä¾‹ï¼ˆå°è§„æ¨¡æ¼”ç¤ºï¼‰
    print("\n1ï¸âƒ£ Pandasï¼ˆå³æ—¶æ‰§è¡Œï¼‰:")
    print("   - æ‰€æœ‰æ“ä½œç«‹å³æ‰§è¡Œ")
    print("   - æ•°æ®å…¨éƒ¨åŠ è½½åˆ°å†…å­˜")
    print("   - å¤§æ•°æ®é›†ä¼šå¯¼è‡´å†…å­˜æº¢å‡º")

    # å°è§„æ¨¡æ¼”ç¤º
    N_small = 1_000_000
    print(f"\n   æ¼”ç¤ºï¼šç”Ÿæˆ{N_small:,}è¡Œæ•°æ®")

    df_pandas = pd.DataFrame({
        'id': range(N_small),
        'value': np.random.randn(N_small)
    })

    print(f"   âœ… æˆåŠŸï¼å†…å­˜ä½¿ç”¨: {df_pandas.memory_usage(deep=True).sum() / 1024**2:.2f} MB")

    # Sparkç¤ºä¾‹ï¼ˆæ¦‚å¿µè¯´æ˜ï¼‰
    print("\n2ï¸âƒ£ Sparkï¼ˆæ‡’æ‰§è¡Œï¼‰:")
    print("   - æ“ä½œæ„å»ºæ‰§è¡Œè®¡åˆ’")
    print("   - åªæœ‰é‡åˆ°Actionæ‰çœŸæ­£æ‰§è¡Œ")
    print("   - æ•°æ®åˆ†åŒºå¤„ç†ï¼Œå¯ä»¥spillåˆ°ç£ç›˜")
    print("   - åªè¿”å›æœ€ç»ˆç»“æœï¼Œä¸æ˜¯å…¨éƒ¨æ•°æ®")

    spark_concept = """
    # Sparkä»£ç ç¤ºä¾‹
    df_spark = spark.range(100_000_000)  # è¿™ä¸ä¼šç«‹å³æ‰§è¡Œ
    df_spark = df_spark.withColumn("value", F.randn())  # ä»ç„¶ä¸æ‰§è¡Œ
    count = df_spark.count()  # è¿™æ˜¯Actionï¼Œè§¦å‘æ‰§è¡Œ
    # ä½†åªè¿”å›countå€¼ï¼Œä¸æ˜¯å…¨éƒ¨æ•°æ®
    """

    print(f"\n   ä»£ç ç¤ºä¾‹ï¼š")
    print(spark_concept)

    print("\nğŸ’¡ å…³é”®åŒºåˆ«ï¼š")
    print("   - Pandas: å¿…é¡»å°†å…¨éƒ¨æ•°æ®åŠ è½½åˆ°å†…å­˜")
    print("   - Spark: åˆ†åŒºå¤„ç†ï¼Œåªè¿”å›èšåˆç»“æœ")
    print("   - åœ¨N=100,000,000æ—¶ï¼ŒPandasä¼šå´©æºƒï¼ŒSparkèƒ½å®Œæˆ")

    return N_small, df_pandas, np, pd, spark_concept


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    ## ğŸ“Š ä½•æ—¶ä½¿ç”¨Sparkï¼Ÿ

    ### ä½¿ç”¨Sparkçš„åœºæ™¯

    1. **æ•°æ®é‡å·¨å¤§**
       - æ•°åäº¿æ¡è®°å½•
       - æ•°æ®å¤§å°è¶…è¿‡å•æœºå†…å­˜
       - éœ€è¦å¤„ç†TBçº§åˆ«çš„æ•°æ®

    2. **æ•°æ®åˆ†å¸ƒå¼å­˜å‚¨**
       - æ•°æ®å­˜å‚¨åœ¨HDFS
       - æ•°æ®åœ¨æ•°æ®æ¹–ä¸­
       - éœ€è¦ä»å¤šä¸ªæ•°æ®æºè¯»å–

    3. **å¤æ‚çš„æ•°æ®å¤„ç†**
       - å¤§è§„æ¨¡joinæ“ä½œ
       - å¤æ‚çš„èšåˆè®¡ç®—
       - éœ€è¦å¹¶è¡Œå¤„ç†

    ### å®é™…æ¡ˆä¾‹

    **åœºæ™¯**ï¼šç½‘ç«™ç”¨æˆ·äº¤äº’æ—¥å¿—åˆ†æ

    - æ•°æ®é‡ï¼š10äº¿æ¡äº‹ä»¶è®°å½•
    - å­˜å‚¨ï¼šParquetæ ¼å¼åœ¨HDFSä¸Š
    - ä»»åŠ¡ï¼šä¸ºæµå¤±æ¨¡å‹åˆ›å»ºç”¨æˆ·ç‰¹å¾ï¼ˆå¹³å‡ä¼šè¯æ—¶é—´ç­‰ï¼‰

    **ä¸ºä»€ä¹ˆç”¨Sparkï¼Ÿ**
    - Pandasæ— æ³•å¤„ç†å¦‚æ­¤å¤§çš„æ•°æ®é‡
    - Sparkå¯ä»¥åˆ†å¸ƒå¼group byç”¨æˆ·å¹¶è®¡ç®—èšåˆ
    - æ›´å¿«ã€æ›´é«˜æ•ˆ

    ### ä¸éœ€è¦Sparkçš„åœºæ™¯

    - æ•°æ® < å‡ ç™¾ä¸‡è¡Œ
    - æ•°æ® < å‡ GB
    - å•æœºå†…å­˜è¶³å¤Ÿ
    - å¿«é€ŸåŸå‹å¼€å‘

    **æ³¨æ„**ï¼šå‰é¢çš„10,000è¡Œç¤ºä¾‹æ›´é€‚åˆç”¨Pandasï¼Œä»£ç ä»…ç”¨äºæ¼”ç¤ºSparkçš„ä½¿ç”¨æ–¹å¼ã€‚
    """
    )
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    ## âš ï¸ Sparkçš„å±€é™æ€§

    è™½ç„¶Sparkå¾ˆå¼ºå¤§ï¼Œä½†å®ƒå¹¶éä¸‡èƒ½ï¼š

    ### æ€§èƒ½ç“¶é¢ˆ

    - **ç½‘ç»œå’ŒI/O**ï¼šå¯èƒ½æˆä¸ºç“¶é¢ˆ
    - **ç®—æ³•é™åˆ¶**ï¼šä¸æ˜¯æ‰€æœ‰ç®—æ³•éƒ½èƒ½è½»æ¾å¹¶è¡ŒåŒ–
    - **å°æ•°æ®å¼€é”€**ï¼šå¯¹äºå°æ•°æ®é›†ï¼Œå¯åŠ¨å¼€é”€å¯èƒ½è¶…è¿‡æ”¶ç›Š

    ### è°ƒè¯•å›°éš¾

    - åˆ†å¸ƒå¼ç¯å¢ƒä¸‹è°ƒè¯•æ›´å¤æ‚
    - éœ€è¦ç†Ÿæ‚‰æ—¥å¿—ç³»ç»Ÿ
    - æ€§èƒ½é—®é¢˜è¯Šæ–­éœ€è¦ç»éªŒ

    ### å­¦ä¹ æ›²çº¿

    - éœ€è¦ç†è§£åˆ†å¸ƒå¼è®¡ç®—æ¦‚å¿µ
    - éœ€è¦äº†è§£Sparkçš„æ‰§è¡Œæ¨¡å‹
    - é…ç½®å’Œè°ƒä¼˜éœ€è¦ç»éªŒ

    ### æ€»ç»“

    Apache Sparkå°†ç®¡é“æ‰©å±•åˆ°å¤§æ•°æ®è§„æ¨¡ï¼Œè®©å›¢é˜Ÿèƒ½å¤Ÿå®ç°åˆ†å¸ƒå¼ETLç”šè‡³å»ºæ¨¡ã€‚åœ¨MLOpsç¯å¢ƒä¸­ï¼Œç†Ÿæ‚‰Sparkæ„å‘³ç€ä½ å¯ä»¥åˆ›å»ºåˆ©ç”¨åˆ†å¸ƒå¼ç‰¹æ€§çš„ç®¡é“ï¼Œè¿™åœ¨ç”Ÿäº§ç¯å¢ƒä¸­å¤„ç†æµ·é‡æ•°æ®æ—¶æ˜¯å¿…éœ€çš„ã€‚

    **å…³é”®åŸåˆ™**ï¼šåœ¨éœ€è¦æ—¶ä½¿ç”¨å®ƒã€‚å¯¹äºè®¸å¤šMLOpsä»»åŠ¡ï¼Œå°æ•°æ®å·¥å…·å°±è¶³å¤Ÿäº†ï¼Œä½†å½“ä½ é‡åˆ°å¤§æ•°æ®é¢†åŸŸæˆ–éœ€è¦å¹¶è¡Œå¤„ç†çš„èƒ½åŠ›æ—¶ï¼ŒSparkï¼ˆæˆ–ç±»ä¼¼æ¡†æ¶ï¼‰å°±å˜å¾—ä¸å¯æˆ–ç¼ºã€‚
    """
    )
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    ---

    ## ğŸ”„ å·¥ä½œæµç¼–æ’ä¸ç®¡ç†

    æ„å»ºç®¡é“æ˜¯ä¸€å›äº‹ï¼Œå¯é åœ°æŒ‰è®¡åˆ’æˆ–å“åº”äº‹ä»¶è¿è¡Œå®ƒæ˜¯å¦ä¸€å›äº‹ã€‚å·¥ä½œæµç¼–æ’å·¥å…·ï¼ˆå¦‚Prefectï¼‰æ—¨åœ¨ç®¡ç†å…·æœ‰å¤šä¸ªæ­¥éª¤ã€ä¾èµ–å…³ç³»å’Œè°ƒåº¦éœ€æ±‚çš„å¤æ‚ç®¡é“ã€‚

    ### ä¸ºä»€ä¹ˆéœ€è¦ç¼–æ’ï¼Ÿ

    åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ï¼ŒMLç®¡é“éœ€è¦ï¼š

    - **å®šæ—¶æ‰§è¡Œ**ï¼šæ¯å¤©ã€æ¯å°æ—¶æˆ–æŒ‰éœ€è¿è¡Œ
    - **ä¾èµ–ç®¡ç†**ï¼šç¡®ä¿ä»»åŠ¡æŒ‰æ­£ç¡®é¡ºåºæ‰§è¡Œ
    - **é”™è¯¯å¤„ç†**ï¼šè‡ªåŠ¨é‡è¯•å¤±è´¥çš„ä»»åŠ¡
    - **ç›‘æ§**ï¼šè·Ÿè¸ªæ‰§è¡ŒçŠ¶æ€å’Œæ€§èƒ½
    - **å¯è§‚æµ‹æ€§**ï¼šæ—¥å¿—ã€æŒ‡æ ‡ã€å‘Šè­¦

    ### ç¼–æ’å·¥å…·çš„ä½œç”¨

    - è°ƒåº¦å’Œè‡ªåŠ¨åŒ–ç®¡é“
    - ç®¡ç†ä»»åŠ¡ä¾èµ–å…³ç³»
    - å¤„ç†å¤±è´¥å’Œé‡è¯•
    - æä¾›ç›‘æ§å’Œå¯è§‚æµ‹æ€§
    - æ”¯æŒå¤šç§æ‰§è¡Œç¯å¢ƒ
    """
    )
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    ## ğŸ¯ Prefectï¼šç°ä»£å·¥ä½œæµç¼–æ’

    Prefectæ˜¯ä¸€ä¸ªå¼€æºçš„ç¼–æ’å·¥å…·ï¼ˆä¹Ÿæœ‰Cloud/Enterpriseç‰ˆæœ¬ï¼‰ï¼Œè®¾è®¡å¾—æ¯”æ—§çš„åŸºäºDAGçš„ç³»ç»Ÿï¼ˆå¦‚Airflowï¼‰æ›´Pythonicå’Œçµæ´»ã€‚

    ### æ ¸å¿ƒæ¦‚å¿µ

    #### 1. Flows & Tasks

    - **Task**ï¼šä½¿ç”¨`@task`è£…é¥°å™¨å°†Pythonå‡½æ•°è½¬æ¢ä¸ºä»»åŠ¡
    - **Flow**ï¼šä½¿ç”¨`@flow`è£…é¥°å™¨å°†ä»»åŠ¡ç»„åˆæˆå·¥ä½œæµ
    - **ä¾èµ–æ¨æ–­**ï¼šä»å‡½æ•°è°ƒç”¨æ–¹å¼è‡ªåŠ¨æ¨æ–­ä¾èµ–å…³ç³»

    #### 2. åŠ¨æ€å·¥ä½œæµ

    - å¯ä»¥åœ¨flowå†…ä½¿ç”¨æ ‡å‡†Pythonæ§åˆ¶æµï¼ˆ`if`ã€`for`ç­‰ï¼‰
    - ä¸éœ€è¦æ˜¾å¼å®šä¹‰DAG
    - æ›´çµæ´»ã€æ›´æ˜“äºç†è§£

    #### 3. æ‰§è¡Œåç«¯

    - æœ¬åœ°æ‰§è¡Œ
    - Daskåˆ†å¸ƒå¼æ‰§è¡Œ
    - Dockerå®¹å™¨
    - Kubernetes
    - äº‘å¹³å°ï¼ˆAWSã€GCPã€Azureï¼‰

    #### 4. Agent/Workeræ¨¡å‹

    - Workerè½®è¯¢å·¥ä½œæ± è·å–è°ƒåº¦çš„flowè¿è¡Œ
    - å¯ä»¥åœ¨ä¸åŒç¯å¢ƒä¸­è¿è¡Œflow
    - æ— éœ€ä¿æŒç»ˆç«¯æ‰“å¼€

    ### DAGï¼ˆæœ‰å‘æ— ç¯å›¾ï¼‰

    **ä»€ä¹ˆæ˜¯DAGï¼Ÿ**

    - **èŠ‚ç‚¹**ï¼šä»»åŠ¡ï¼ˆå¦‚è·å–æ•°æ®ã€å¤„ç†æ•°æ®ã€è®­ç»ƒæ¨¡å‹ï¼‰
    - **è¾¹**ï¼šä¾èµ–å…³ç³»ï¼ˆå¦‚è®­ç»ƒä¾èµ–äºå¤„ç†ï¼Œå¤„ç†ä¾èµ–äºè·å–ï¼‰
    - **æœ‰å‘**ï¼šä»»åŠ¡å¿…é¡»æŒ‰å®šä¹‰çš„é¡ºåºæ‰§è¡Œ
    - **æ— ç¯**ï¼šæ²¡æœ‰å¾ªç¯ï¼Œé¿å…æ— é™è¿è¡Œ

    **Prefect vs Airflowï¼š**

    - Airflowï¼šæ˜¾å¼å®šä¹‰DAG
    - Prefectï¼šä»Pythonä»£ç éšå¼æ„å»ºDAG
    """
    )
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    ## ğŸ’» Prefectç¤ºä¾‹ï¼šç®€å•çš„MLç®¡é“

    è®©æˆ‘ä»¬é€šè¿‡ä¸€ä¸ªç®€å•çš„ç¤ºä¾‹æ¥ç†è§£Prefectçš„å·¥ä½œæ–¹å¼ã€‚
    """
    )
    return


@app.cell
def _():
    print("ğŸ’» Prefectå·¥ä½œæµç¤ºä¾‹")
    print("=" * 50)

    prefect_example = """
from prefect import task, flow
import time

@task(retries=2, retry_delay_seconds=5)
def fetch_data():
    '''æ¨¡æ‹Ÿä»æ•°æ®æºè·å–æ•°æ®'''
    print("ğŸ“¥ æ­£åœ¨è·å–æ•°æ®...")
    time.sleep(1)
    # æ¨¡æ‹Ÿæ•°æ®
    data = {"records": 1000, "features": 10}
    print(f"âœ… è·å–äº† {data['records']} æ¡è®°å½•")
    return data

@task(retries=2, retry_delay_seconds=5)
def process_data(raw_data):
    '''æ¨¡æ‹Ÿæ•°æ®å¤„ç†'''
    print("ğŸ”„ æ­£åœ¨å¤„ç†æ•°æ®...")
    time.sleep(1)
    processed = {
        "records": raw_data["records"],
        "features": raw_data["features"] + 5  # æ·»åŠ äº†5ä¸ªæ–°ç‰¹å¾
    }
    print(f"âœ… å¤„ç†å®Œæˆï¼Œç°åœ¨æœ‰ {processed['features']} ä¸ªç‰¹å¾")
    return processed

@task(retries=2, retry_delay_seconds=5)
def train_model(processed_data):
    '''æ¨¡æ‹Ÿæ¨¡å‹è®­ç»ƒ'''
    print("ğŸ“ æ­£åœ¨è®­ç»ƒæ¨¡å‹...")
    time.sleep(2)
    accuracy = 0.85
    print(f"âœ… æ¨¡å‹è®­ç»ƒå®Œæˆï¼Œå‡†ç¡®ç‡: {accuracy:.2%}")
    return {"accuracy": accuracy, "model_id": "model_v1"}

@flow(name="ml-pipeline")
def ml_pipeline():
    '''å®Œæ•´çš„MLç®¡é“'''
    print("ğŸš€ å¼€å§‹MLç®¡é“æ‰§è¡Œ")

    # ä¾èµ–å…³ç³»è‡ªåŠ¨æ¨æ–­
    raw = fetch_data()
    processed = process_data(raw)
    model = train_model(processed)

    print(f"ğŸ‰ ç®¡é“æ‰§è¡Œå®Œæˆï¼æ¨¡å‹ID: {model['model_id']}")
    return model

# è¿è¡Œflow
if __name__ == "__main__":
    result = ml_pipeline()
    """

    print("\nğŸ“ Prefectä»£ç ç¤ºä¾‹ï¼š")
    print(prefect_example)

    print("\nğŸ” å…³é”®ç‰¹æ€§ï¼š")
    print("   1. @taskè£…é¥°å™¨ï¼šä½¿å‡½æ•°å¯é‡è¯•ã€å¯ç›‘æ§ã€å¯è§‚æµ‹")
    print("   2. @flowè£…é¥°å™¨ï¼šå®šä¹‰å·¥ä½œæµ")
    print("   3. ä¾èµ–æ¨æ–­ï¼šä»å‡½æ•°è°ƒç”¨è‡ªåŠ¨æ¨æ–­ä¾èµ–å…³ç³»")
    print("   4. é‡è¯•æœºåˆ¶ï¼šè‡ªåŠ¨å¤„ç†ç¬æ—¶å¤±è´¥")
    print("   5. æ—¥å¿—è®°å½•ï¼šè‡ªåŠ¨è®°å½•æ‰§è¡Œæ—¥å¿—")

    return (prefect_example,)


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    ## ğŸ“… Prefectè°ƒåº¦

    Prefectæ”¯æŒå¤šç§è°ƒåº¦æ–¹å¼ï¼š

    ### 1. Cronè°ƒåº¦

    ä¼ ç»Ÿçš„åŸºäºæ—¶é—´çš„è°ƒåº¦ï¼š

    ```yaml
    schedules:
      - cron: "0 2 * * *"  # æ¯å¤©å‡Œæ™¨2ç‚¹
        timezone: "Asia/Shanghai"
    ```

    **å¸¸ç”¨Cronè¡¨è¾¾å¼ï¼š**
    - `0 * * * *`ï¼šæ¯å°æ—¶
    - `0 0 * * *`ï¼šæ¯å¤©åˆå¤œ
    - `0 0 * * 1`ï¼šæ¯å‘¨ä¸€
    - `0 0 1 * *`ï¼šæ¯æœˆ1å·

    ### 2. é—´éš”è°ƒåº¦

    æŒ‰å›ºå®šé—´éš”è¿è¡Œï¼š

    ```yaml
    schedules:
      - interval: 30  # æ¯30ç§’
    ```

    **é€‚ç”¨åœºæ™¯ï¼š**
    - å®æ—¶æ•°æ®å¤„ç†
    - é¢‘ç¹çš„æ•°æ®åŒæ­¥
    - ç›‘æ§ä»»åŠ¡

    ### 3. äº‹ä»¶é©±åŠ¨è§¦å‘

    å“åº”äº‹ä»¶è¿è¡Œï¼š

    - æ–‡ä»¶åˆ°è¾¾S3
    - Webhookè§¦å‘
    - ä¸Šæ¸¸ä»»åŠ¡å®Œæˆ
    - è‡ªå®šä¹‰äº‹ä»¶

    **ä¼˜åŠ¿ï¼š**
    - ä¸éœ€è¦è½®è¯¢
    - æŒ‰éœ€è¿è¡Œ
    - èŠ‚çœèµ„æº
    """
    )
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    ## ğŸ›ï¸ Prefectéƒ¨ç½²é…ç½®

    ### prefect.yamlç¤ºä¾‹

    ```yaml
    name: ml-pipeline-project

    deployments:
      - name: ml-pipeline-deployment
        entrypoint: pipeline.py:ml_pipeline
        work_pool:
          name: default-agent-pool
        schedules:
          - interval: 30
            timezone: "Asia/Shanghai"
    ```

    ### è¿è¡ŒPrefect Flow

    #### å¼€å‘æ¨¡å¼

    ```bash
    # ç›´æ¥è¿è¡Œï¼ˆç«‹å³æ‰§è¡Œï¼‰
    python pipeline.py
    ```

    #### ç”Ÿäº§æ¨¡å¼

    ```bash
    # 1. å¯åŠ¨PrefectæœåŠ¡å™¨
    prefect server start

    # 2. åˆ›å»ºéƒ¨ç½²
    prefect deploy

    # 3. å¯åŠ¨worker
    prefect worker start --pool default-agent-pool
    ```

    ### Prefect UI

    Prefectæä¾›äº†ä¸€ä¸ªç°ä»£åŒ–çš„Web UIï¼š

    - æŸ¥çœ‹flowè¿è¡Œå†å²
    - ç›‘æ§ä»»åŠ¡çŠ¶æ€
    - æŸ¥çœ‹æ—¥å¿—
    - ç®¡ç†è°ƒåº¦
    - é…ç½®å‘Šè­¦

    **è®¿é—®æ–¹å¼ï¼š**
    - æœ¬åœ°ï¼š`http://localhost:4200`
    - Prefect Cloudï¼šæ‰˜ç®¡æœåŠ¡
    """
    )
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    ## ğŸ† è°ƒåº¦æœ€ä½³å®è·µ

    æ— è®ºä½¿ç”¨å“ªä¸ªç¼–æ’å·¥å…·ï¼ˆAirflowã€Prefectç­‰ï¼‰ï¼Œä»¥ä¸‹æœ€ä½³å®è·µéƒ½é€‚ç”¨ï¼š

    ### 1. æ˜æ™ºä½¿ç”¨Cron/æ—¶é—´è°ƒåº¦

    - **ç•™å‡ºç¼“å†²æ—¶é—´**ï¼šå¦‚æœæ•°æ®åœ¨å‡Œæ™¨1ç‚¹å¯ç”¨ï¼Œè°ƒåº¦åœ¨3ç‚¹è¿è¡Œ
    - **è€ƒè™‘æ—¶åŒº**ï¼šæ˜ç¡®æŒ‡å®šæ—¶åŒºï¼Œé¿å…æ··æ·†
    - **é¿å…é«˜å³°æœŸ**ï¼šä¸è¦åœ¨ç³»ç»Ÿè´Ÿè½½é«˜çš„æ—¶å€™è°ƒåº¦

    ### 2. äº‹ä»¶é©±åŠ¨è§¦å‘

    - **æŒ‰éœ€è¿è¡Œ**ï¼šåªåœ¨éœ€è¦æ—¶è¿è¡Œï¼ŒèŠ‚çœèµ„æº
    - **å‡å°‘è½®è¯¢**ï¼šä½¿ç”¨äº‹ä»¶é€šçŸ¥è€Œä¸æ˜¯å®šæœŸæ£€æŸ¥
    - **é›†æˆå¤–éƒ¨ç³»ç»Ÿ**ï¼šäº‘å­˜å‚¨é€šçŸ¥ã€Webhookç­‰

    ### 3. é‡è¯•å’Œå¹‚ç­‰æ€§

    - **é…ç½®é‡è¯•**ï¼šä¸ºæ˜“å¤±è´¥çš„ä»»åŠ¡è®¾ç½®é‡è¯•
    - **å¹‚ç­‰æ€§**ï¼šç¡®ä¿ä»»åŠ¡å¯ä»¥å®‰å…¨åœ°é‡å¤è¿è¡Œ
    - **é¿å…å‰¯ä½œç”¨**ï¼šå¤±è´¥é‡è¯•ä¸åº”ç ´åæ•°æ®

    **å¹‚ç­‰æ€§ç¤ºä¾‹ï¼š**

    ```python
    # âŒ éå¹‚ç­‰
    def append_data(data):
        existing = load_data()
        existing.append(data)  # é‡è¯•ä¼šé‡å¤æ·»åŠ 
        save_data(existing)

    # âœ… å¹‚ç­‰
    def upsert_data(data):
        existing = load_data()
        existing[data.id] = data  # é‡è¯•åªæ˜¯è¦†ç›–
        save_data(existing)
    ```

    ### 4. ç¯å¢ƒéš”ç¦»

    - **å¼€å‘/æµ‹è¯•/ç”Ÿäº§åˆ†ç¦»**ï¼šä½¿ç”¨ä¸åŒçš„é¡¹ç›®æˆ–å‘½åç©ºé—´
    - **é¿å…å†²çª**ï¼šæµ‹è¯•ä¸åº”å½±å“ç”Ÿäº§
    - **é…ç½®ç®¡ç†**ï¼šä½¿ç”¨ç¯å¢ƒå˜é‡ç®¡ç†é…ç½®

    ### 5. å®¹å™¨åŒ–

    - **Dockerå®¹å™¨**ï¼šç¡®ä¿ç¯å¢ƒä¸€è‡´æ€§
    - **ç‰ˆæœ¬é”å®š**ï¼šå›ºå®šä¾èµ–ç‰ˆæœ¬
    - **é¿å…"åœ¨æˆ‘æœºå™¨ä¸Šèƒ½è¿è¡Œ"**ï¼šå®¹å™¨åŒ–æ¶ˆé™¤ç¯å¢ƒå·®å¼‚

    ### 6. æ–‡æ¡£åŒ–

    - **è®°å½•ç®¡é“ç”¨é€”**ï¼šæ¯ä¸ªç®¡é“åšä»€ä¹ˆ
    - **è®°å½•è°ƒåº¦**ï¼šä½•æ—¶è¿è¡Œã€ä¸ºä»€ä¹ˆ
    - **è®°å½•ä¾èµ–**ï¼šä¸Šæ¸¸/ä¸‹æ¸¸æ•°æ®
    - **ä½¿ç”¨æè¿°**ï¼šåœ¨ç¼–æ’å·¥å…·ä¸­æ·»åŠ æè¿°
    """
    )
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    ## ğŸ“Š Spark vs Pandas vs Prefectï¼šå·¥å…·å¯¹æ¯”

    è®©æˆ‘ä»¬é€šè¿‡ä¸€ä¸ªè¡¨æ ¼æ¥æ€»ç»“è¿™äº›å·¥å…·çš„ç‰¹ç‚¹å’Œä½¿ç”¨åœºæ™¯ï¼š
    """
    )
    return


@app.cell
def _(mo, pd):
    tools_comparison = pd.DataFrame([
        {
            "å·¥å…·": "Pandas",
            "ç”¨é€”": "æ•°æ®å¤„ç†",
            "é€‚ç”¨åœºæ™¯": "å°åˆ°ä¸­ç­‰æ•°æ®é›†ï¼ˆ<å‡ GBï¼‰",
            "ä¼˜åŠ¿": "ç®€å•æ˜“ç”¨ã€å¿«é€Ÿã€ä¸°å¯ŒAPI",
            "åŠ£åŠ¿": "å—é™äºå•æœºå†…å­˜",
            "å…¸å‹ä½¿ç”¨": "æ¢ç´¢æ€§åˆ†æã€åŸå‹å¼€å‘ã€ç‰¹å¾å·¥ç¨‹"
        },
        {
            "å·¥å…·": "Spark",
            "ç”¨é€”": "å¤§æ•°æ®å¤„ç†",
            "é€‚ç”¨åœºæ™¯": "å¤§æ•°æ®é›†ï¼ˆ>å‡ GBï¼Œæ•°åäº¿è¡Œï¼‰",
            "ä¼˜åŠ¿": "åˆ†å¸ƒå¼ã€å¯æ‰©å±•ã€å®¹é”™",
            "åŠ£åŠ¿": "å¯åŠ¨å¼€é”€å¤§ã€è°ƒè¯•å›°éš¾",
            "å…¸å‹ä½¿ç”¨": "å¤§è§„æ¨¡ETLã€åˆ†å¸ƒå¼è®­ç»ƒã€æ•°æ®æ¹–å¤„ç†"
        },
        {
            "å·¥å…·": "Prefect",
            "ç”¨é€”": "å·¥ä½œæµç¼–æ’",
            "é€‚ç”¨åœºæ™¯": "å¤æ‚ç®¡é“ã€ç”Ÿäº§ç¯å¢ƒ",
            "ä¼˜åŠ¿": "çµæ´»ã€Pythonicã€æ˜“äºç›‘æ§",
            "åŠ£åŠ¿": "éœ€è¦é¢å¤–åŸºç¡€è®¾æ–½",
            "å…¸å‹ä½¿ç”¨": "è°ƒåº¦MLç®¡é“ã€ä¾èµ–ç®¡ç†ã€è‡ªåŠ¨åŒ–"
        }
    ])

    mo.md(f"""
    ### å·¥å…·å¯¹æ¯”è¡¨

    {tools_comparison.to_markdown(index=False)}

    ### ç»„åˆä½¿ç”¨

    åœ¨å®é™…çš„MLOpsç³»ç»Ÿä¸­ï¼Œè¿™äº›å·¥å…·é€šå¸¸ç»„åˆä½¿ç”¨ï¼š

    1. **Pandas + Prefect**ï¼š
       - å°åˆ°ä¸­ç­‰æ•°æ®é›†çš„MLç®¡é“
       - Prefectè°ƒåº¦å’Œç¼–æ’
       - Pandaså¤„ç†æ•°æ®å’Œç‰¹å¾å·¥ç¨‹

    2. **Spark + Prefect**ï¼š
       - å¤§æ•°æ®MLç®¡é“
       - Prefectè°ƒåº¦å’Œç¼–æ’
       - Sparkå¤„ç†å¤§è§„æ¨¡æ•°æ®

    3. **Pandas + Spark + Prefect**ï¼š
       - æ··åˆç®¡é“
       - Sparkå¤„ç†å¤§æ•°æ®ETL
       - Pandaså¤„ç†èšåˆåçš„æ•°æ®
       - Prefectç¼–æ’æ•´ä¸ªæµç¨‹
    """)

    return (tools_comparison,)


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    ## ğŸ¯ å®è·µå»ºè®®

    ### å­¦ä¹ è·¯å¾„

    #### 1. æŒæ¡åŸºç¡€

    - **Pandas**ï¼šæ•°æ®å¤„ç†åŸºç¡€
    - **Scikit-learn**ï¼šæœºå™¨å­¦ä¹ åŸºç¡€
    - **Python**ï¼šç¼–ç¨‹åŸºç¡€

    #### 2. ç†è§£åˆ†å¸ƒå¼è®¡ç®—

    - **SparkåŸºç¡€**ï¼šRDDã€DataFrameã€Transformationsã€Actions
    - **Spark SQL**ï¼šåˆ†å¸ƒå¼SQLæŸ¥è¯¢
    - **Spark MLlib**ï¼šåˆ†å¸ƒå¼æœºå™¨å­¦ä¹ 

    #### 3. å­¦ä¹ å·¥ä½œæµç¼–æ’

    - **PrefectåŸºç¡€**ï¼šTasksã€Flowsã€Deployments
    - **è°ƒåº¦ç­–ç•¥**ï¼šCronã€Intervalã€Event-driven
    - **ç›‘æ§å’Œæ—¥å¿—**ï¼šUIã€æ—¥å¿—åˆ†æ

    ### å®è·µé¡¹ç›®

    #### é¡¹ç›®1ï¼šå°è§„æ¨¡MLç®¡é“

    - ä½¿ç”¨Pandaså¤„ç†æ•°æ®
    - ä½¿ç”¨Scikit-learnè®­ç»ƒæ¨¡å‹
    - ä½¿ç”¨Prefectè°ƒåº¦å’Œç›‘æ§

    #### é¡¹ç›®2ï¼šå¤§è§„æ¨¡æ•°æ®å¤„ç†

    - ä½¿ç”¨Sparkå¤„ç†å¤§æ•°æ®é›†
    - å®ç°åˆ†å¸ƒå¼ç‰¹å¾å·¥ç¨‹
    - ä½¿ç”¨Spark MLlibè®­ç»ƒæ¨¡å‹

    #### é¡¹ç›®3ï¼šç«¯åˆ°ç«¯MLOpsç³»ç»Ÿ

    - Sparkè¿›è¡Œå¤§è§„æ¨¡ETL
    - Pandasè¿›è¡Œç‰¹å¾å·¥ç¨‹
    - Scikit-learnè®­ç»ƒæ¨¡å‹
    - Prefectç¼–æ’æ•´ä¸ªæµç¨‹
    - Dockerå®¹å™¨åŒ–
    - ç›‘æ§å’Œå‘Šè­¦

    ### æ¨èèµ„æº

    #### Sparkå­¦ä¹ èµ„æº

    - **å®˜æ–¹æ–‡æ¡£**ï¼šhttps://spark.apache.org/docs/latest/
    - **PySparkæ•™ç¨‹**ï¼šhttps://spark.apache.org/docs/latest/api/python/
    - **Sparkæƒå¨æŒ‡å—**ï¼šä¹¦ç±æ¨è

    #### Prefectå­¦ä¹ èµ„æº

    - **å®˜æ–¹æ–‡æ¡£**ï¼šhttps://docs.prefect.io/
    - **æ•™ç¨‹**ï¼šhttps://docs.prefect.io/tutorials/
    - **ç¤¾åŒº**ï¼šhttps://discourse.prefect.io/

    #### MLOpså­¦ä¹ èµ„æº

    - **MLOpsç¤¾åŒº**ï¼šhttps://mlops.community/
    - **è®ºæ–‡å’Œåšå®¢**ï¼šå…³æ³¨æœ€æ–°ç ”ç©¶å’Œå®è·µ
    - **å¼€æºé¡¹ç›®**ï¼šå‚ä¸å’Œå­¦ä¹ 
    """
    )
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    ## ğŸ“ æ€»ç»“

    åœ¨æœ¬ç« ä¸­ï¼Œæˆ‘ä»¬æ·±å…¥æ¢è®¨äº†MLOpsä¸­çš„æ•°æ®å’Œç®¡é“å·¥ç¨‹ï¼š

    ### å…³é”®è¦ç‚¹

    #### Apache Spark

    1. **åˆ†å¸ƒå¼è®¡ç®—å¼•æ“**ï¼šå¤„ç†è¶…å¤§æ•°æ®é›†
    2. **DataFrame API**ï¼šç±»ä¼¼Pandasä½†åˆ†å¸ƒå¼
    3. **MLlib**ï¼šåˆ†å¸ƒå¼æœºå™¨å­¦ä¹ åº“
    4. **æ‡’æ‰§è¡Œ**ï¼šä¼˜åŒ–æ‰§è¡Œè®¡åˆ’
    5. **å®¹é”™æœºåˆ¶**ï¼šè‡ªåŠ¨å¤„ç†å¤±è´¥

    #### Pandas vs Spark

    1. **Pandas**ï¼šå°æ•°æ®ã€å¿«é€Ÿã€ç®€å•
    2. **Spark**ï¼šå¤§æ•°æ®ã€åˆ†å¸ƒå¼ã€å¯æ‰©å±•
    3. **é€‰æ‹©æ ‡å‡†**ï¼šæ•°æ®å¤§å°ã€å¤æ‚åº¦ã€èµ„æº
    4. **ç»„åˆä½¿ç”¨**ï¼šå‘æŒ¥å„è‡ªä¼˜åŠ¿

    #### Prefectå·¥ä½œæµç¼–æ’

    1. **Tasks & Flows**ï¼šæ„å»ºç®¡é“
    2. **è°ƒåº¦ç­–ç•¥**ï¼šCronã€Intervalã€Event-driven
    3. **é‡è¯•æœºåˆ¶**ï¼šå¤„ç†å¤±è´¥
    4. **ç›‘æ§UI**ï¼šå¯è§‚æµ‹æ€§
    5. **çµæ´»éƒ¨ç½²**ï¼šå¤šç§æ‰§è¡Œç¯å¢ƒ

    #### æœ€ä½³å®è·µ

    1. **æ˜æ™ºè°ƒåº¦**ï¼šè€ƒè™‘æ—¶åŒºã€ç¼“å†²æ—¶é—´
    2. **å¹‚ç­‰æ€§**ï¼šå®‰å…¨é‡è¯•
    3. **ç¯å¢ƒéš”ç¦»**ï¼šå¼€å‘/æµ‹è¯•/ç”Ÿäº§åˆ†ç¦»
    4. **å®¹å™¨åŒ–**ï¼šç¯å¢ƒä¸€è‡´æ€§
    5. **æ–‡æ¡£åŒ–**ï¼šè®°å½•æ‰€æœ‰å†…å®¹

    ### ä¸‹ä¸€æ­¥

    åœ¨æ¥ä¸‹æ¥çš„ç« èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†ç»§ç»­æ¢è®¨ï¼š

    - **æ¨¡å‹å¼€å‘å’Œå®è·µ**ï¼šè®­ç»ƒã€è¯„ä¼°ã€ä¼˜åŒ–
    - **CI/CDå·¥ä½œæµ**ï¼šä¸ºMLç³»ç»Ÿå®šåˆ¶
    - **çœŸå®æ¡ˆä¾‹ç ”ç©¶**ï¼šè¡Œä¸šå®è·µ
    - **ç›‘æ§å’Œè§‚æµ‹**ï¼šç”Ÿäº§ç¯å¢ƒ
    - **LLMOpsç‰¹æ®Šè€ƒè™‘**ï¼šå¤§è¯­è¨€æ¨¡å‹è¿ç»´

    ### æ ¸å¿ƒç†å¿µ

    MLOpsä¸ä»…ä»…æ˜¯å·¥å…·å’ŒæŠ€æœ¯ï¼Œæ›´æ˜¯ä¸€ç§æ€ç»´æ–¹å¼ï¼š

    - **ç³»ç»Ÿæ€ç»´**ï¼šå°†MLè§†ä¸ºè½¯ä»¶ç³»ç»Ÿçš„ä¸€éƒ¨åˆ†
    - **è‡ªåŠ¨åŒ–ä¼˜å…ˆ**ï¼šå‡å°‘æ‰‹åŠ¨æ“ä½œ
    - **å¯è§‚æµ‹æ€§**ï¼šäº†è§£ç³»ç»ŸçŠ¶æ€
    - **æŒç»­æ”¹è¿›**ï¼šè¿­ä»£ä¼˜åŒ–
    - **å›¢é˜Ÿåä½œ**ï¼šè·¨èŒèƒ½åˆä½œ

    é€šè¿‡ç»“åˆæ‰å®çš„æ•°æ®å·¥ç¨‹ï¼ˆETLã€é‡‡æ ·ã€é¿å…æ³„æ¼ï¼‰ã€å¥å£®çš„ç®¡é“å’Œå·¥ä½œæµç¼–æ’ï¼Œä½ å¯ä»¥æ„å»ºå¯æ‰©å±•ã€å¯é çš„MLç³»ç»Ÿã€‚

    è®°ä½ï¼š**æ·±å…¥ç†è§£åº•å±‚ç³»ç»Ÿè®¾è®¡å’Œç”Ÿå‘½å‘¨æœŸåŸåˆ™ï¼Œä½ å°±èƒ½å¤Ÿé©¾é©­ä»»ä½•æŠ€æœ¯æ ˆã€‚** ğŸš€
    """
    )
    return


@app.cell
def _():
    from datetime import datetime
    return (datetime,)


if __name__ == "__main__":
    app.run()

