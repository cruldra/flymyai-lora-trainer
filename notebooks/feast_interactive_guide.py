import marimo

__generated_with = "0.16.5"
app = marimo.App(width="medium")


@app.cell
def _():
    import marimo as mo
    return (mo,)


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    # Feastç‰¹å¾å­˜å‚¨å®Œå…¨æŒ‡å—

    ## ğŸ¯ ä»€ä¹ˆæ˜¯Feastï¼Ÿ

    **Feastï¼ˆFeature Storeï¼‰** æ˜¯ä¸€ä¸ªå¼€æºçš„ç‰¹å¾å­˜å‚¨ç³»ç»Ÿï¼Œä¸“é—¨ä¸ºæœºå™¨å­¦ä¹ å·¥ä½œæµè®¾è®¡ã€‚å®ƒè§£å†³äº†MLç³»ç»Ÿä¸­ç‰¹å¾ç®¡ç†çš„æ ¸å¿ƒæŒ‘æˆ˜ï¼š**å¦‚ä½•åœ¨è®­ç»ƒå’ŒæœåŠ¡ä¹‹é—´ä¿æŒç‰¹å¾çš„ä¸€è‡´æ€§**ã€‚

    ### æ ¸å¿ƒé—®é¢˜

    åœ¨ä¼ ç»Ÿçš„MLå¼€å‘ä¸­ï¼Œæˆ‘ä»¬ç»å¸¸é‡åˆ°ä»¥ä¸‹é—®é¢˜ï¼š

    1. **è®­ç»ƒ-æœåŠ¡åå·®**ï¼šè®­ç»ƒæ—¶çš„ç‰¹å¾è®¡ç®—é€»è¾‘ä¸ç”Ÿäº§æœåŠ¡æ—¶ä¸ä¸€è‡´
    2. **ç‰¹å¾é‡å¤å¼€å‘**ï¼šä¸åŒå›¢é˜Ÿé‡å¤å®ç°ç›¸åŒçš„ç‰¹å¾
    3. **æ•°æ®æ³„æ¼é£é™©**ï¼šç‰¹å¾è®¡ç®—ä¸­æ„å¤–ä½¿ç”¨äº†æœªæ¥ä¿¡æ¯
    4. **ç‰¹å¾å‘ç°å›°éš¾**ï¼šå›¢é˜Ÿä¸çŸ¥é“å·²æœ‰å“ªäº›ç‰¹å¾å¯ç”¨
    5. **å®æ—¶ç‰¹å¾æœåŠ¡**ï¼šç”Ÿäº§ç¯å¢ƒéœ€è¦ä½å»¶è¿Ÿçš„ç‰¹å¾æŸ¥è¯¢

    ### Feastçš„è§£å†³æ–¹æ¡ˆ

    - **ç»Ÿä¸€ç‰¹å¾å®šä¹‰**ï¼šä¸€æ¬¡å®šä¹‰ï¼Œè®­ç»ƒå’ŒæœåŠ¡éƒ½ä½¿ç”¨ç›¸åŒé€»è¾‘
    - **æ—¶é—´ç‚¹æ­£ç¡®æ€§**ï¼šç¡®ä¿è®­ç»ƒæ•°æ®ä¸åŒ…å«æœªæ¥ä¿¡æ¯
    - **ç‰¹å¾é‡ç”¨**ï¼šé›†ä¸­ç®¡ç†ï¼Œé¿å…é‡å¤å¼€å‘
    - **åœ¨çº¿/ç¦»çº¿å­˜å‚¨**ï¼šæ”¯æŒè®­ç»ƒï¼ˆæ‰¹é‡ï¼‰å’ŒæœåŠ¡ï¼ˆå®æ—¶ï¼‰ä¸¤ç§åœºæ™¯
    """
    )
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    ## ğŸ—ï¸ Feastæ ¸å¿ƒæ¦‚å¿µ

    è®©æˆ‘ä»¬é€šè¿‡äº¤äº’å¼ä»£ç æ¥ç†è§£Feastçš„æ ¸å¿ƒæ¦‚å¿µï¼š
    """
    )
    return


@app.cell
def _():
    # å®‰è£…å¿…è¦çš„åŒ…ï¼ˆå¦‚æœéœ€è¦ï¼‰
    import subprocess
    import sys

    def install_package(package):
        try:
            __import__(package)
        except ImportError:
            print(f"å®‰è£… {package}...")
            subprocess.check_call([sys.executable, "-m", "pip", "install", package])

    # å°è¯•å®‰è£…feastï¼ˆå¦‚æœæœªå®‰è£…ï¼‰
    try:
        import feast
        print("âœ… Feastå·²å®‰è£…")
    except ImportError:
        print("âš ï¸ Feastæœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install feast")

    # å¯¼å…¥å…¶ä»–å¿…è¦çš„åº“
    import pandas as pd
    import numpy as np
    from datetime import datetime, timedelta
    import warnings
    warnings.filterwarnings('ignore')

    print("ğŸ“¦ ä¾èµ–åŒ…å¯¼å…¥å®Œæˆ")
    return datetime, np, pd, timedelta


@app.cell
def _(mo):
    mo.md(
        r"""
    ### 1. Entityï¼ˆå®ä½“ï¼‰
    å®ä½“æ˜¯ç‰¹å¾çš„ä¸»é”®ï¼Œå®šä¹‰äº†ç‰¹å¾å±äºå“ªä¸ªå¯¹è±¡ã€‚
    """
    )
    return


@app.cell
def _():
    # å®šä¹‰å®¢æˆ·å®ä½“
    from feast import Entity
    from feast.types import ValueType

    customer = Entity(
        name="customer_id",
        value_type=ValueType.STRING,
        description="å®¢æˆ·å”¯ä¸€æ ‡è¯†ç¬¦"
    )

    print("âœ… å®¢æˆ·å®ä½“å®šä¹‰å®Œæˆ")
    print(f"å®ä½“åç§°: {customer.name}")
    print(f"å€¼ç±»å‹: {customer.value_type}")
    print(f"æè¿°: {customer.description}")
    return (customer,)


@app.cell
def _(mo):
    mo.md(
        r"""
    ### 2. Feature Viewï¼ˆç‰¹å¾è§†å›¾ï¼‰
    ç‰¹å¾è§†å›¾å®šä¹‰äº†ä¸€ç»„ç›¸å…³ç‰¹å¾åŠå…¶è®¡ç®—é€»è¾‘ã€‚
    """
    )
    return


@app.cell
def _(customer, timedelta):
    from feast import FeatureView, Field, FileSource
    from feast.types import Float32, Int64, String

    # å®šä¹‰æ•°æ®æº
    customer_source = FileSource(
        path="data/customer_features.parquet",
        timestamp_field="event_timestamp"
    )

    # å®šä¹‰å®¢æˆ·äººå£ç»Ÿè®¡ç‰¹å¾è§†å›¾
    customer_demographics = FeatureView(
        name="customer_demographics",
        entities=[customer],
        ttl=timedelta(days=365),  # ç‰¹å¾çš„ç”Ÿå­˜æ—¶é—´
        schema=[
            Field(name="age", dtype=Int64),
            Field(name="income", dtype=Float32),
            Field(name="credit_score", dtype=Int64),
        ],
        source=customer_source,
        tags={"team": "ml", "domain": "demographics"}
    )

    # å®šä¹‰å®¢æˆ·è¡Œä¸ºç‰¹å¾è§†å›¾
    customer_behavior = FeatureView(
        name="customer_behavior",
        entities=[customer],
        ttl=timedelta(days=90),
        schema=[
            Field(name="monthly_charges", dtype=Float32),
            Field(name="total_charges", dtype=Float32),
            Field(name="support_calls", dtype=Int64),
            Field(name="contract_length", dtype=Int64),
        ],
        source=customer_source,
        tags={"team": "ml", "domain": "behavior"}
    )

    print("âœ… ç‰¹å¾è§†å›¾å®šä¹‰å®Œæˆ")
    print(f"äººå£ç»Ÿè®¡ç‰¹å¾: {[f.name for f in customer_demographics.schema]}")
    print(f"è¡Œä¸ºç‰¹å¾: {[f.name for f in customer_behavior.schema]}")
    return customer_behavior, customer_demographics, customer_source


@app.cell
def _(customer_behavior, customer_demographics):
    # å®šä¹‰ç‰¹å¾æœåŠ¡
    from feast import FeatureService

    feature_refs = [
        customer_demographics[["age", "income", "credit_score"]],
        customer_behavior[["monthly_charges", "total_charges", "support_calls", "contract_length"]],
    ]

    churn_prediction_service = FeatureService(
        name="churn_prediction",
        features=feature_refs
    )

    print("âœ… ç‰¹å¾æœåŠ¡å®šä¹‰å®Œæˆ")
    print(f"æœåŠ¡åç§°: {churn_prediction_service.name}")
    print(f"åŒ…å«ç‰¹å¾æ•°é‡: {len(feature_refs)}")
    return churn_prediction_service, feature_refs


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    ## ğŸ“Š å®é™…æ¡ˆä¾‹ï¼šå®¢æˆ·æµå¤±é¢„æµ‹

    è®©æˆ‘ä»¬é€šè¿‡ä¸€ä¸ªå®Œæ•´çš„å®¢æˆ·æµå¤±é¢„æµ‹æ¡ˆä¾‹æ¥æ¼”ç¤ºFeastçš„ä½¿ç”¨ã€‚
    """
    )
    return


@app.cell
def _(datetime, np, pd, timedelta):
    # ç”Ÿæˆç¤ºä¾‹å®¢æˆ·æ•°æ®
    def generate_customer_data():
        """ç”Ÿæˆç¤ºä¾‹å®¢æˆ·æ•°æ®ç”¨äºæ¼”ç¤º"""
        np.random.seed(42)
        n_customers = 100  # ä¸ºäº†æ¼”ç¤ºï¼Œä½¿ç”¨è¾ƒå°çš„æ•°æ®é›†

        # ç”Ÿæˆå®¢æˆ·åŸºç¡€ä¿¡æ¯
        customer_data = []
        base_date = datetime(2023, 1, 1)

        for i in range(n_customers):
            customer_id = f"customer_{i:04d}"

            # ç”Ÿæˆå¤šä¸ªæ—¶é—´ç‚¹çš„æ•°æ®
            for days_offset in [0, 30, 60, 90]:
                event_time = base_date + timedelta(days=days_offset)

                customer_data.append({
                    'customer_id': customer_id,
                    'event_timestamp': event_time,
                    'age': np.random.randint(18, 80),
                    'income': max(20000, np.random.normal(50000, 20000)),
                    'credit_score': np.random.randint(300, 850),
                    'monthly_charges': max(10, np.random.normal(65, 20)),
                    'total_charges': max(0, np.random.normal(1000, 500)),
                    'support_calls': np.random.poisson(2),
                    'contract_length': np.random.choice([1, 12, 24], p=[0.5, 0.3, 0.2])
                })

        df = pd.DataFrame(customer_data)

        # ç¡®ä¿æ•°æ®ç±»å‹æ­£ç¡®
        df['income'] = df['income'].astype('float32')
        df['monthly_charges'] = df['monthly_charges'].astype('float32')
        df['total_charges'] = df['total_charges'].astype('float32')

        return df

    # ç”Ÿæˆæ•°æ®
    customer_df = generate_customer_data()

    print(f"âœ… ç”Ÿæˆäº† {len(customer_df)} æ¡å®¢æˆ·ç‰¹å¾è®°å½•")
    print(f"ğŸ“Š æ•°æ®å½¢çŠ¶: {customer_df.shape}")
    print(f"ğŸ‘¥ å”¯ä¸€å®¢æˆ·æ•°: {customer_df['customer_id'].nunique()}")
    print(f"ğŸ“… æ—¶é—´èŒƒå›´: {customer_df['event_timestamp'].min()} åˆ° {customer_df['event_timestamp'].max()}")

    # æ˜¾ç¤ºæ•°æ®æ ·æœ¬
    print("\nğŸ“‹ æ•°æ®æ ·æœ¬:")
    customer_df.head()
    return (customer_df,)


@app.cell
def _(customer_df):
    # æ•°æ®è´¨é‡æ£€æŸ¥
    print("ğŸ” æ•°æ®è´¨é‡æ£€æŸ¥:")
    print(f"ç¼ºå¤±å€¼ç»Ÿè®¡:")
    missing_stats = customer_df.isnull().sum()
    for col, col_missing_count in missing_stats.items():
        if col_missing_count > 0:
            print(f"  {col}: {col_missing_count} ({col_missing_count/len(customer_df)*100:.1f}%)")

    if missing_stats.sum() == 0:
        print("  âœ… æ— ç¼ºå¤±å€¼")

    print(f"\nğŸ“ˆ æ•°å€¼ç‰¹å¾ç»Ÿè®¡:")
    numeric_cols = ['age', 'income', 'credit_score', 'monthly_charges', 'total_charges', 'support_calls']
    customer_df[numeric_cols].describe()
    return missing_stats, numeric_cols


@app.cell
def _(customer_df, mo):
    # åˆ›å»ºæ•°æ®ç›®å½•å¹¶ä¿å­˜æ•°æ®
    import os

    # åˆ›å»ºæ•°æ®ç›®å½•
    os.makedirs('data', exist_ok=True)

    # ä¿å­˜æ•°æ®
    customer_df.to_parquet('data/customer_features.parquet', index=False)

    mo.md(f"""
    âœ… **æ•°æ®å·²ä¿å­˜åˆ° `data/customer_features.parquet`**

    - æ–‡ä»¶å¤§å°: {os.path.getsize('data/customer_features.parquet') / 1024:.1f} KB
    - è®°å½•æ•°: {len(customer_df):,}
    - åˆ—æ•°: {len(customer_df.columns)}
    """)
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    ### ğŸ¯ åˆ›å»ºFeasté…ç½®

    ç°åœ¨æˆ‘ä»¬éœ€è¦åˆ›å»ºFeastçš„é…ç½®æ–‡ä»¶ã€‚åœ¨å®é™…é¡¹ç›®ä¸­ï¼Œè¿™é€šå¸¸æ˜¯ä¸€ä¸ªå•ç‹¬çš„Pythonæ–‡ä»¶ã€‚
    """
    )
    return


@app.cell
def _(
    churn_prediction_service,
    customer,
    customer_behavior,
    customer_demographics,
):
    # åˆ›å»ºfeature_store.pyé…ç½®ï¼ˆæ¨¡æ‹Ÿï¼‰
    feature_store_config = f"""
    # feature_store.py - Feasté…ç½®æ–‡ä»¶

    from feast import Entity, FeatureView, Field, FileSource, FeatureService
    from feast.types import Float32, Int64, String
    from datetime import timedelta

    # å®šä¹‰å®ä½“
    {repr(customer)}

    # å®šä¹‰æ•°æ®æº
    customer_source = FileSource(
    path="data/customer_features.parquet",
    timestamp_field="event_timestamp"
    )

    # å®šä¹‰ç‰¹å¾è§†å›¾
    {repr(customer_demographics)}

    {repr(customer_behavior)}

    # å®šä¹‰ç‰¹å¾æœåŠ¡
    {repr(churn_prediction_service)}
    """

    print("ğŸ“ Feasté…ç½®æ–‡ä»¶å†…å®¹:")
    print("=" * 50)
    print(feature_store_config[:500] + "...")
    print("=" * 50)

    # ä¿å­˜é…ç½®æ–‡ä»¶
    with open('feature_store.py', 'w', encoding='utf-8') as f:
        f.write(feature_store_config)

    print("âœ… é…ç½®æ–‡ä»¶å·²ä¿å­˜ä¸º feature_store.py")
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    ### ğŸš€ åˆå§‹åŒ–Feastå­˜å‚¨

    ç°åœ¨è®©æˆ‘ä»¬åˆå§‹åŒ–Feastç‰¹å¾å­˜å‚¨å¹¶åº”ç”¨æˆ‘ä»¬çš„é…ç½®ã€‚
    """
    )
    return


@app.cell
def _():
    # åˆå§‹åŒ–Feastå­˜å‚¨
    try:
        from feast import FeatureStore

        # åˆ›å»ºç‰¹å¾å­˜å‚¨å®ä¾‹
        store = FeatureStore(repo_path=".")

        print("âœ… Feastç‰¹å¾å­˜å‚¨åˆå§‹åŒ–æˆåŠŸ")
        print(f"å­˜å‚¨è·¯å¾„: {store.repo_path}")

        # å°è¯•åº”ç”¨é…ç½®ï¼ˆåœ¨å®é™…ç¯å¢ƒä¸­éœ€è¦è¿è¡Œ feast applyï¼‰
        print("\nğŸ“‹ å¯ç”¨çš„ç‰¹å¾è§†å›¾:")
        try:
            feature_views = store.list_feature_views()
            for fv in feature_views:
                print(f"  - {fv.name}: {len(fv.schema)} ä¸ªç‰¹å¾")
        except Exception as e:
            print("  âš ï¸ éœ€è¦å…ˆè¿è¡Œ 'feast apply' æ¥åº”ç”¨é…ç½®")
            print(f"  é”™è¯¯: {str(e)}")

    except Exception as e:
        print(f"âŒ Feaståˆå§‹åŒ–å¤±è´¥: {str(e)}")
        print("è¯·ç¡®ä¿å·²å®‰è£…Feast: pip install feast")
        store = None
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    ### ğŸ“Š ç”Ÿæˆè®­ç»ƒæ•°æ®

    è®©æˆ‘ä»¬åˆ›å»ºè®­ç»ƒæ ‡ç­¾å¹¶ç”Ÿæˆæ—¶é—´ç‚¹æ­£ç¡®çš„è®­ç»ƒæ•°æ®é›†ã€‚
    """
    )
    return


@app.cell
def _(datetime, np, pd):
    # åˆ›å»ºè®­ç»ƒæ ‡ç­¾æ•°æ®
    def create_training_labels():
        """åˆ›å»ºè®­ç»ƒæ ‡ç­¾æ•°æ®"""
        np.random.seed(42)

        # é€‰æ‹©ä¸€äº›å®¢æˆ·å’Œæ—¶é—´ç‚¹è¿›è¡Œé¢„æµ‹
        customer_ids = [f"customer_{i:04d}" for i in range(0, 50, 5)]  # æ¯5ä¸ªå®¢æˆ·é€‰1ä¸ª
        prediction_times = [
            datetime(2023, 2, 1),
            datetime(2023, 3, 1),
            datetime(2023, 4, 1)
        ]

        entity_rows = []
        for customer_id in customer_ids:
            for pred_time in prediction_times:
                # æ¨¡æ‹Ÿæµå¤±æ ‡ç­¾ï¼ˆåŸºäºä¸€äº›ä¸šåŠ¡é€»è¾‘ï¼‰
                # è¿™é‡Œä½¿ç”¨ç®€å•çš„éšæœºç”Ÿæˆï¼Œå®é™…ä¸­ä¼šåŸºäºçœŸå®ä¸šåŠ¡è§„åˆ™
                churn_prob = np.random.random()
                churn_label = 1 if churn_prob > 0.8 else 0

                entity_rows.append({
                    "customer_id": customer_id,
                    "event_timestamp": pred_time,
                    "churn_label": churn_label
                })

        return pd.DataFrame(entity_rows)

    # åˆ›å»ºå®ä½“DataFrame
    entity_df = create_training_labels()

    print("âœ… è®­ç»ƒæ ‡ç­¾æ•°æ®åˆ›å»ºå®Œæˆ")
    print(f"ğŸ“Š æ ‡ç­¾æ•°æ®å½¢çŠ¶: {entity_df.shape}")
    print(f"ğŸ‘¥ æ¶‰åŠå®¢æˆ·æ•°: {entity_df['customer_id'].nunique()}")
    print(f"ğŸ“… é¢„æµ‹æ—¶é—´ç‚¹: {entity_df['event_timestamp'].nunique()}")
    print(f"âš–ï¸ æµå¤±ç‡: {entity_df['churn_label'].mean():.1%}")

    print("\nğŸ“‹ æ ‡ç­¾æ•°æ®æ ·æœ¬:")
    entity_df.head(10)
    return (entity_df,)


@app.cell
def _(customer_df, entity_df, pd):
    # æ¨¡æ‹Ÿå†å²ç‰¹å¾è·å–ï¼ˆå› ä¸ºå¯èƒ½æ²¡æœ‰å®Œæ•´çš„Feastç¯å¢ƒï¼‰
    def simulate_historical_features(entity_df, customer_df):
        """æ¨¡æ‹Ÿå†å²ç‰¹å¾è·å–è¿‡ç¨‹"""

        print("ğŸ”„ æ¨¡æ‹Ÿå†å²ç‰¹å¾è·å–...")

        # ä¸ºæ¯ä¸ªå®ä½“è¡Œæ‰¾åˆ°å¯¹åº”çš„å†å²ç‰¹å¾
        training_rows = []

        for _, row in entity_df.iterrows():
            customer_id = row['customer_id']
            event_timestamp = row['event_timestamp']
            churn_label = row['churn_label']

            # æ‰¾åˆ°è¯¥å®¢æˆ·åœ¨è¯¥æ—¶é—´ç‚¹ä¹‹å‰çš„æœ€æ–°ç‰¹å¾
            customer_features = customer_df[
                (customer_df['customer_id'] == customer_id) &
                (customer_df['event_timestamp'] <= event_timestamp)
            ].sort_values('event_timestamp').tail(1)

            if not customer_features.empty:
                feature_row = customer_features.iloc[0].to_dict()
                feature_row['churn_label'] = churn_label
                training_rows.append(feature_row)

        return pd.DataFrame(training_rows)

    # ç”Ÿæˆè®­ç»ƒæ•°æ®
    training_df = simulate_historical_features(entity_df, customer_df)

    print("âœ… è®­ç»ƒæ•°æ®ç”Ÿæˆå®Œæˆ")
    print(f"ğŸ“Š è®­ç»ƒæ•°æ®å½¢çŠ¶: {training_df.shape}")
    print(f"ğŸ¯ ç‰¹å¾åˆ—æ•°: {len([col for col in training_df.columns if col != 'churn_label'])}")

    # æ£€æŸ¥ç¼ºå¤±å€¼
    total_missing = training_df.isnull().sum().sum()
    if total_missing == 0:
        print("âœ… æ— ç¼ºå¤±å€¼")
    else:
        print(f"âš ï¸ å‘ç° {total_missing} ä¸ªç¼ºå¤±å€¼")

    print("\nğŸ“‹ è®­ç»ƒæ•°æ®æ ·æœ¬:")
    training_df.head()
    return total_missing, training_df


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    ### ğŸ¤– æ¨¡å‹è®­ç»ƒ

    ç°åœ¨è®©æˆ‘ä»¬ä½¿ç”¨ç”Ÿæˆçš„è®­ç»ƒæ•°æ®æ¥è®­ç»ƒä¸€ä¸ªå®¢æˆ·æµå¤±é¢„æµ‹æ¨¡å‹ã€‚
    """
    )
    return


@app.cell
def _(pd, training_df):
    from sklearn.model_selection import train_test_split
    from sklearn.ensemble import RandomForestClassifier
    from sklearn.preprocessing import StandardScaler
    from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix
    import joblib

    def train_churn_model(training_df):
        """è®­ç»ƒå®¢æˆ·æµå¤±é¢„æµ‹æ¨¡å‹"""

        print("ğŸ¤– å¼€å§‹è®­ç»ƒå®¢æˆ·æµå¤±é¢„æµ‹æ¨¡å‹...")

        # å‡†å¤‡ç‰¹å¾å’Œæ ‡ç­¾
        feature_columns = [
            'age', 'income', 'credit_score', 'monthly_charges',
            'total_charges', 'support_calls', 'contract_length'
        ]

        X = training_df[feature_columns].fillna(0)  # ç®€å•å¤„ç†ç¼ºå¤±å€¼
        y = training_df['churn_label']

        print(f"ğŸ“Š ç‰¹å¾çŸ©é˜µå½¢çŠ¶: {X.shape}")
        print(f"ğŸ¯ æ ‡ç­¾åˆ†å¸ƒ: æµå¤±={y.sum()}, æœªæµå¤±={len(y)-y.sum()}")

        # åˆ†å‰²æ•°æ®
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.3, random_state=42, stratify=y
        )

        # ç‰¹å¾æ ‡å‡†åŒ–
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)

        # è®­ç»ƒæ¨¡å‹
        model = RandomForestClassifier(
            n_estimators=100,
            random_state=42,
            class_weight='balanced'  # å¤„ç†ç±»åˆ«ä¸å¹³è¡¡
        )

        model.fit(X_train_scaled, y_train)

        # è¯„ä¼°æ¨¡å‹
        y_pred = model.predict(X_test_scaled)
        y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]

        print("\nğŸ“ˆ æ¨¡å‹è¯„ä¼°ç»“æœ:")
        print("=" * 40)
        print(classification_report(y_test, y_pred))

        try:
            auc_score = roc_auc_score(y_test, y_pred_proba)
            print(f"ğŸ¯ AUC Score: {auc_score:.3f}")
        except ValueError:
            print("âš ï¸ æ— æ³•è®¡ç®—AUCï¼ˆå¯èƒ½åªæœ‰ä¸€ä¸ªç±»åˆ«ï¼‰")

        # ç‰¹å¾é‡è¦æ€§
        feature_importance = pd.DataFrame({
            'feature': feature_columns,
            'importance': model.feature_importances_
        }).sort_values('importance', ascending=False)

        print("\nğŸ” ç‰¹å¾é‡è¦æ€§:")
        for _, row in feature_importance.head().iterrows():
            print(f"  {row['feature']}: {row['importance']:.3f}")

        # ä¿å­˜æ¨¡å‹å’Œé¢„å¤„ç†å™¨
        joblib.dump(model, 'churn_model.pkl')
        joblib.dump(scaler, 'feature_scaler.pkl')

        print("\nâœ… æ¨¡å‹è®­ç»ƒå®Œæˆå¹¶å·²ä¿å­˜")

        return model, scaler, feature_importance

    # è®­ç»ƒæ¨¡å‹
    model, scaler, feature_importance = train_churn_model(training_df)
    return feature_importance, model, scaler


@app.cell
def _(feature_importance, mo):
    # å¯è§†åŒ–ç‰¹å¾é‡è¦æ€§
    import matplotlib.pyplot as plt

    plt.figure(figsize=(10, 6))
    plt.barh(feature_importance['feature'], feature_importance['importance'])
    plt.xlabel('é‡è¦æ€§åˆ†æ•°')
    plt.title('ç‰¹å¾é‡è¦æ€§æ’åº')
    plt.gca().invert_yaxis()

    # åœ¨marimoä¸­æ˜¾ç¤ºå›¾è¡¨
    mo.md(f"""
    ## ğŸ“Š ç‰¹å¾é‡è¦æ€§åˆ†æ

    æ ¹æ®éšæœºæ£®æ—æ¨¡å‹çš„åˆ†æï¼Œå„ç‰¹å¾çš„é‡è¦æ€§æ’åºå¦‚ä¸‹ï¼š

    {feature_importance.to_string(index=False)}
    """)
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    ### ğŸŒ åœ¨çº¿ç‰¹å¾æœåŠ¡

    ç°åœ¨è®©æˆ‘ä»¬æ¨¡æ‹Ÿåœ¨çº¿ç‰¹å¾æœåŠ¡ï¼Œå±•ç¤ºå¦‚ä½•åœ¨ç”Ÿäº§ç¯å¢ƒä¸­è¿›è¡Œå®æ—¶é¢„æµ‹ã€‚
    """
    )
    return


@app.cell
def _(customer_df, datetime, model, pd, scaler):
    def simulate_online_features(customer_ids, current_time=None):
        """æ¨¡æ‹Ÿåœ¨çº¿ç‰¹å¾è·å–"""

        if current_time is None:
            current_time = datetime.now()

        print(f"ğŸ”„ æ¨¡æ‹Ÿåœ¨çº¿ç‰¹å¾è·å– (æ—¶é—´: {current_time})")

        # æ¨¡æ‹Ÿä»åœ¨çº¿å­˜å‚¨è·å–æœ€æ–°ç‰¹å¾
        online_features_list = []

        for customer_id in customer_ids:
            # è·å–è¯¥å®¢æˆ·çš„æœ€æ–°ç‰¹å¾
            customer_features = customer_df[
                customer_df['customer_id'] == customer_id
            ].sort_values('event_timestamp').tail(1)

            if not customer_features.empty:
                features = customer_features.iloc[0].to_dict()
                features['customer_id'] = customer_id
                online_features_list.append(features)
            else:
                print(f"âš ï¸ å®¢æˆ· {customer_id} æœªæ‰¾åˆ°ç‰¹å¾æ•°æ®")

        return pd.DataFrame(online_features_list)

    def predict_churn_online(customer_ids):
        """ä½¿ç”¨åœ¨çº¿ç‰¹å¾è¿›è¡Œå®æ—¶é¢„æµ‹"""

        print(f"ğŸ¯ ä¸º {len(customer_ids)} ä¸ªå®¢æˆ·è¿›è¡Œæµå¤±é¢„æµ‹...")

        # è·å–åœ¨çº¿ç‰¹å¾
        features_df = simulate_online_features(customer_ids)

        if features_df.empty:
            print("âŒ æœªè·å–åˆ°ç‰¹å¾æ•°æ®")
            return []

        print(f"âœ… è·å–åˆ° {len(features_df)} ä¸ªå®¢æˆ·çš„ç‰¹å¾")

        # å‡†å¤‡é¢„æµ‹æ•°æ®
        feature_columns = [
            'age', 'income', 'credit_score', 'monthly_charges',
            'total_charges', 'support_calls', 'contract_length'
        ]

        X = features_df[feature_columns].fillna(0)

        # åŠ è½½æ¨¡å‹å’Œé¢„å¤„ç†å™¨
        try:
            # ä½¿ç”¨å·²è®­ç»ƒçš„æ¨¡å‹
            X_scaled = scaler.transform(X)
            predictions = model.predict_proba(X_scaled)[:, 1]

            # ç”Ÿæˆç»“æœ
            results = []
            for i, customer_id in enumerate(features_df['customer_id']):
                risk_level = (
                    'High' if predictions[i] > 0.7
                    else 'Medium' if predictions[i] > 0.3
                    else 'Low'
                )

                results.append({
                    'customer_id': customer_id,
                    'churn_probability': predictions[i],
                    'risk_level': risk_level,
                    'prediction_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                })

            return results

        except Exception as e:
            print(f"âŒ é¢„æµ‹å¤±è´¥: {str(e)}")
            return []

    # è¿›è¡Œåœ¨çº¿é¢„æµ‹æ¼”ç¤º
    test_customers = ["customer_0000", "customer_0005", "customer_0010", "customer_0015"]
    predictions = predict_churn_online(test_customers)

    print("\nğŸ¯ å®æ—¶é¢„æµ‹ç»“æœ:")
    print("=" * 60)
    for pred in predictions:
        print(f"å®¢æˆ· {pred['customer_id']}: "
              f"æµå¤±æ¦‚ç‡ {pred['churn_probability']:.3f} "
              f"({pred['risk_level']} Risk)")
    print("=" * 60)

    # è½¬æ¢ä¸ºDataFrameä¾¿äºæ˜¾ç¤º
    predictions_df = pd.DataFrame(predictions)
    predictions_df
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    ### ğŸ” ç‰¹å¾ç›‘æ§å’Œè´¨é‡æ£€æŸ¥

    åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ï¼Œç›‘æ§ç‰¹å¾è´¨é‡æ˜¯éå¸¸é‡è¦çš„ã€‚è®©æˆ‘ä»¬å®ç°ä¸€äº›åŸºæœ¬çš„ç›‘æ§åŠŸèƒ½ã€‚
    """
    )
    return


@app.cell
def _(customer_df, timedelta):
    def monitor_feature_quality(df, time_window_days=7):
        """ç›‘æ§ç‰¹å¾è´¨é‡"""

        print(f"ğŸ” ç‰¹å¾è´¨é‡ç›‘æ§ (æœ€è¿‘ {time_window_days} å¤©)")
        print("=" * 50)

        # è®¡ç®—æ—¶é—´çª—å£
        end_date = df['event_timestamp'].max()
        start_date = end_date - timedelta(days=time_window_days)

        recent_data = df[df['event_timestamp'] >= start_date]

        print(f"ğŸ“… ç›‘æ§æ—¶é—´èŒƒå›´: {start_date.date()} åˆ° {end_date.date()}")
        print(f"ğŸ“Š ç›‘æ§æ•°æ®é‡: {len(recent_data)} æ¡è®°å½•")

        # æ•°æ®è´¨é‡æ£€æŸ¥
        quality_report = {}

        numeric_columns = ['age', 'income', 'credit_score', 'monthly_charges', 'total_charges', 'support_calls']

        for col in numeric_columns:
            col_data = recent_data[col]

            quality_report[col] = {
                'missing_rate': col_data.isnull().mean(),
                'mean': col_data.mean(),
                'std': col_data.std(),
                'min': col_data.min(),
                'max': col_data.max(),
                'outlier_rate': ((col_data < col_data.quantile(0.01)) |
                               (col_data > col_data.quantile(0.99))).mean()
            }

        # æ˜¾ç¤ºè´¨é‡æŠ¥å‘Š
        print("\nğŸ“‹ ç‰¹å¾è´¨é‡æŠ¥å‘Š:")
        for feature, stats in quality_report.items():
            print(f"\nğŸ”§ {feature}:")
            print(f"  ç¼ºå¤±ç‡: {stats['missing_rate']:.1%}")
            print(f"  å‡å€¼: {stats['mean']:.2f}")
            print(f"  æ ‡å‡†å·®: {stats['std']:.2f}")
            print(f"  å¼‚å¸¸å€¼ç‡: {stats['outlier_rate']:.1%}")

            # è´¨é‡è­¦å‘Š
            if stats['missing_rate'] > 0.1:
                print(f"  âš ï¸ è­¦å‘Š: ç¼ºå¤±ç‡è¿‡é«˜ ({stats['missing_rate']:.1%})")
            if stats['outlier_rate'] > 0.05:
                print(f"  âš ï¸ è­¦å‘Š: å¼‚å¸¸å€¼è¿‡å¤š ({stats['outlier_rate']:.1%})")

        return quality_report

    # æ‰§è¡Œç‰¹å¾è´¨é‡ç›‘æ§
    quality_report = monitor_feature_quality(customer_df)
    return


@app.cell
def _(customer_df, pd):
    def detect_data_drift(df, reference_period_days=30, current_period_days=7):
        """æ£€æµ‹æ•°æ®æ¼‚ç§»"""

        print("ğŸŒŠ æ•°æ®æ¼‚ç§»æ£€æµ‹")
        print("=" * 40)

        end_date = df['event_timestamp'].max()

        # å‚è€ƒæœŸé—´ï¼ˆåŸºçº¿ï¼‰
        ref_start = end_date - pd.Timedelta(days=reference_period_days + current_period_days)
        ref_end = end_date - pd.Timedelta(days=current_period_days)
        reference_data = df[(df['event_timestamp'] >= ref_start) & (df['event_timestamp'] < ref_end)]

        # å½“å‰æœŸé—´
        current_start = end_date - pd.Timedelta(days=current_period_days)
        current_data = df[df['event_timestamp'] >= current_start]

        print(f"ğŸ“Š å‚è€ƒæœŸé—´: {ref_start.date()} åˆ° {ref_end.date()} ({len(reference_data)} æ¡è®°å½•)")
        print(f"ğŸ“Š å½“å‰æœŸé—´: {current_start.date()} åˆ° {end_date.date()} ({len(current_data)} æ¡è®°å½•)")

        # æ¯”è¾ƒç»Ÿè®¡ç‰¹å¾
        numeric_columns = ['age', 'income', 'credit_score', 'monthly_charges', 'total_charges']

        drift_report = {}

        for col in numeric_columns:
            ref_mean = reference_data[col].mean()
            current_mean = current_data[col].mean()

            ref_std = reference_data[col].std()
            current_std = current_data[col].std()

            # è®¡ç®—å˜åŒ–ç™¾åˆ†æ¯”
            mean_change = (current_mean - ref_mean) / ref_mean * 100 if ref_mean != 0 else 0
            std_change = (current_std - ref_std) / ref_std * 100 if ref_std != 0 else 0

            drift_report[col] = {
                'mean_change_pct': mean_change,
                'std_change_pct': std_change,
                'drift_detected': abs(mean_change) > 10 or abs(std_change) > 20
            }

        print("\nğŸ“ˆ æ¼‚ç§»æ£€æµ‹ç»“æœ:")
        for feature, stats in drift_report.items():
            status = "ğŸš¨ æ£€æµ‹åˆ°æ¼‚ç§»" if stats['drift_detected'] else "âœ… æ­£å¸¸"
            print(f"\n{feature}: {status}")
            print(f"  å‡å€¼å˜åŒ–: {stats['mean_change_pct']:+.1f}%")
            print(f"  æ ‡å‡†å·®å˜åŒ–: {stats['std_change_pct']:+.1f}%")

        return drift_report

    # æ‰§è¡Œæ•°æ®æ¼‚ç§»æ£€æµ‹
    drift_report = detect_data_drift(customer_df)
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    ### ğŸ“š Feastæœ€ä½³å®è·µ

    åŸºäºæˆ‘ä»¬çš„å®é™…æ¡ˆä¾‹ï¼Œè®©æˆ‘ä»¬æ€»ç»“ä¸€äº›Feastä½¿ç”¨çš„æœ€ä½³å®è·µã€‚
    """
    )
    return


@app.cell
def _(mo):
    best_practices = {
        "ç‰¹å¾å‘½åè§„èŒƒ": [
            "âœ… ä½¿ç”¨æè¿°æ€§åç§°ï¼šcustomer_age_years è€Œä¸æ˜¯ age",
            "âœ… åŒ…å«æ—¶é—´çª—å£ï¼špurchases_30d, clicks_7d",
            "âœ… ä½¿ç”¨ä¸€è‡´çš„å‘½åçº¦å®šï¼šsnake_case",
            "âœ… é¿å…ç¼©å†™ï¼šmonthly_revenue è€Œä¸æ˜¯ mon_rev"
        ],

        "ç‰¹å¾ç»„ç»‡": [
            "âœ… æŒ‰ä¸šåŠ¡åŸŸåˆ†ç»„ï¼šcustomer_features, product_features",
            "âœ… æŒ‰æ›´æ–°é¢‘ç‡åˆ†ç»„ï¼šdaily_features, realtime_features",
            "âœ… æŒ‰æ•°æ®æºåˆ†ç»„ï¼šdatabase_features, api_features",
            "âœ… ä½¿ç”¨æ ‡ç­¾è¿›è¡Œåˆ†ç±»å’Œæœç´¢"
        ],

        "æ•°æ®è´¨é‡": [
            "âœ… å®æ–½ç‰¹å¾éªŒè¯ï¼šæ•°æ®ç±»å‹ã€èŒƒå›´æ£€æŸ¥",
            "âœ… ç›‘æ§ç‰¹å¾åˆ†å¸ƒå˜åŒ–ï¼šæ•°æ®æ¼‚ç§»æ£€æµ‹",
            "âœ… è®¾ç½®æ•°æ®è´¨é‡è­¦æŠ¥ï¼šç¼ºå¤±å€¼ã€å¼‚å¸¸å€¼",
            "âœ… å®šæœŸå®¡æŸ¥ç‰¹å¾ä½¿ç”¨æƒ…å†µ"
        ],

        "æ€§èƒ½ä¼˜åŒ–": [
            "âœ… é€‰æ‹©åˆé€‚çš„TTLï¼šå¹³è¡¡æ–°é²œåº¦å’Œå­˜å‚¨æˆæœ¬",
            "âœ… ä¼˜åŒ–æ‰¹å¤„ç†çª—å£ï¼šå‡å°‘è®¡ç®—å¼€é”€",
            "âœ… ä½¿ç”¨é€‚å½“çš„åˆ†åŒºç­–ç•¥ï¼šæé«˜æŸ¥è¯¢æ€§èƒ½",
            "âœ… ç›‘æ§å­˜å‚¨å’Œè®¡ç®—æˆæœ¬"
        ],

        "å®‰å…¨å’Œæ²»ç†": [
            "âœ… å®æ–½è®¿é—®æ§åˆ¶ï¼šåŸºäºè§’è‰²çš„ç‰¹å¾è®¿é—®",
            "âœ… æ•°æ®è¡€ç¼˜è·Ÿè¸ªï¼šäº†è§£ç‰¹å¾æ¥æºå’Œä¾èµ–",
            "âœ… åˆè§„æ€§æ£€æŸ¥ï¼šç¡®ä¿ç¬¦åˆæ•°æ®ä¿æŠ¤æ³•è§„",
            "âœ… å®¡è®¡æ—¥å¿—ï¼šè·Ÿè¸ªç‰¹å¾ä½¿ç”¨å’Œä¿®æ”¹"
        ]
    }

    practices_md = "## ğŸ¯ Feastæœ€ä½³å®è·µæ€»ç»“\n\n"

    for category, items in best_practices.items():
        practices_md += f"### ğŸ“‹ {category}\n\n"
        for item in items:
            practices_md += f"- {item}\n"
        practices_md += "\n"

    mo.md(practices_md)
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    ## ğŸª æ€»ç»“

    é€šè¿‡è¿™ä¸ªäº¤äº’å¼æŒ‡å—ï¼Œæˆ‘ä»¬æ·±å…¥æ¢ç´¢äº†Feastç‰¹å¾å­˜å‚¨çš„æ ¸å¿ƒæ¦‚å¿µå’Œå®é™…åº”ç”¨ï¼š

    ### ğŸ¯ **å…³é”®å­¦ä¹ æˆæœ**

    1. **ç†è§£äº†Feastæ¶æ„**ï¼šEntityã€Feature Viewã€Data Sourceã€Feature Serviceçš„ä½œç”¨å’Œå…³ç³»
    2. **æŒæ¡äº†å®Œæ•´å·¥ä½œæµ**ï¼šä»ç‰¹å¾å®šä¹‰åˆ°æ¨¡å‹éƒ¨ç½²çš„ç«¯åˆ°ç«¯æµç¨‹
    3. **å®ç°äº†å®é™…æ¡ˆä¾‹**ï¼šå®¢æˆ·æµå¤±é¢„æµ‹çš„å®Œæ•´å®ç°
    4. **å­¦ä¹ äº†ç›‘æ§æŠ€æœ¯**ï¼šç‰¹å¾è´¨é‡ç›‘æ§å’Œæ•°æ®æ¼‚ç§»æ£€æµ‹
    5. **æŒæ¡äº†æœ€ä½³å®è·µ**ï¼šç‰¹å¾å‘½åã€ç»„ç»‡ã€è´¨é‡ä¿è¯ç­‰

    ### ğŸš€ **Feastçš„æ ¸å¿ƒä»·å€¼**

    - **ä¸€è‡´æ€§ä¿è¯**ï¼šè®­ç»ƒå’ŒæœåŠ¡ä½¿ç”¨ç›¸åŒçš„ç‰¹å¾å®šä¹‰
    - **æ—¶é—´æ­£ç¡®æ€§**ï¼šé˜²æ­¢æ•°æ®æ³„æ¼ï¼Œç¡®ä¿å†å²æ•°æ®çš„å‡†ç¡®æ€§
    - **å¼€å‘æ•ˆç‡**ï¼šç‰¹å¾é‡ç”¨ï¼Œé¿å…é‡å¤å¼€å‘
    - **è¿ç»´ç®€åŒ–**ï¼šç»Ÿä¸€çš„ç‰¹å¾ç®¡ç†å’Œç›‘æ§
    - **å¯æ‰©å±•æ€§**ï¼šæ”¯æŒä»åŸå‹åˆ°ç”Ÿäº§çš„æ— ç¼æ‰©å±•

    ### ğŸ”® **ä¸‹ä¸€æ­¥è¡ŒåŠ¨**

    1. **å®‰è£…Feast**ï¼š`pip install feast`
    2. **åˆ›å»ºé¡¹ç›®**ï¼š`feast init your_project`
    3. **å®šä¹‰ç‰¹å¾**ï¼šæ ¹æ®ä¸šåŠ¡éœ€æ±‚è®¾è®¡ç‰¹å¾è§†å›¾
    4. **åº”ç”¨é…ç½®**ï¼š`feast apply`
    5. **å¼€å§‹ä½¿ç”¨**ï¼šåœ¨è®­ç»ƒå’ŒæœåŠ¡ä¸­é›†æˆFeast

    Feastæ˜¯ç°ä»£MLOpsæ¶æ„ä¸­ä¸å¯æˆ–ç¼ºçš„ç»„ä»¶ï¼Œå®ƒå°†ç‰¹å¾ç®¡ç†ä»ä¸´æ—¶æ€§çš„å·¥ä½œè½¬å˜ä¸ºç³»ç»Ÿæ€§çš„èƒ½åŠ›ï¼Œä¸ºæ„å»ºå¯é ã€å¯æ‰©å±•çš„MLç³»ç»Ÿå¥ å®šäº†åšå®åŸºç¡€ï¼ğŸ‰
    """
    )
    return


if __name__ == "__main__":
    app.run()
